{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem Statements:\n",
    "#The gestures are continuously monitored by the webcam mounted on the TV. Each gesture corresponds to a specific command\n",
    "#Thumbs up: Increase the Volume\n",
    "#Thumbs down: Drecrease the Volume\n",
    "#Left swipe:'Jump' backwards 10 seconds\n",
    "#Right swipe: 'Jump' forward 10 seconds\n",
    "#Stop: Pause the movie\n",
    "\n",
    "#Each video is a sequence of 30 frames (or images)\n",
    "\n",
    "#Understanding the Dataset\n",
    "#The training data consists of a few hundered videos categorised into one of the five classes.\n",
    "#Each video (typically 2-3 seconds long) is divided into a sequence of 30 frames(images).\n",
    "#These videos have been recorded by various people performing one of the five gestures in front of a webcam\n",
    "#similar to what the smart TV will use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "#from scipy.misc import imread, imresize  #deprecated\n",
    "from matplotlib.pyplot import imread\n",
    "#from scipy.misc import imresize\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from skimage.transform import rescale,resize,downscale_local_mean\n",
    "import datetime\n",
    "import os\n",
    "import cv2\n",
    "import abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)\n",
    "#tf.set_random_seed(30) # deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('./Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('./Project_data/val.csv').readlines())\n",
    "#batch_size = 10 #experiment with the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters initialization\n",
    "nb_rows = 120   # X dimension of the image\n",
    "nb_cols = 120   # Y dimesnion of the image\n",
    "nb_frames = 30  # lenght of the video frames\n",
    "nb_channel = 3 # numbe rof channels in images 3 for color(RGB) and 1 for Gray\n",
    "project_folder=\"./Project_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 10\n"
     ]
    }
   ],
   "source": [
    "# Function to generate a random affine transform on the iamge\n",
    "def get_random_affine():\n",
    "    dx, dy = np.random.randint(-1.7, 1.8, 2)\n",
    "    M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "    return M\n",
    "\n",
    "# Function to normalise the data\n",
    "def normalize_data(data):\n",
    "    return data/127.5-1\n",
    "\n",
    "# Function to initialize all the batch image data and labels\n",
    "def init_batch_data(batch_size):\n",
    "    batch_data = np.zeros((batch_size, nb_frames, nb_rows, nb_cols, nb_channel)) \n",
    "    batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "    return batch_data, batch_labels\n",
    "\n",
    "#Function to train_load_batch_Images\n",
    "def train_load_batch_images(source_path, folder_list, batch_num, batch_size, t):\n",
    "    \n",
    "    batch_data,batch_labels = init_batch_data(batch_size)\n",
    "    # We will also build a agumented batch data\n",
    "    batch_data_aug,batch_labels_aug = init_batch_data(batch_size)\n",
    "\n",
    "    #create a list of image numbers you want to use for a particular video\n",
    "    img_idx = [x for x in range(0, nb_frames)] \n",
    "\n",
    "    for folder in range(batch_size): # iterate over the batch_size\n",
    "        # read all the images in the folder\n",
    "        imgs = sorted(os.listdir(source_path+'/'+ t[folder + (batch_num*batch_size)].split(';')[0])) \n",
    "        # Generate a random affine to be used in image transformation for buidling agumented data set\n",
    "        M = get_random_affine()\n",
    "        \n",
    "        #  Iterate over the frames/images of a folder to read them in\n",
    "        for idx, item in enumerate(img_idx): \n",
    "            image = cv2.imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item], cv2.IMREAD_COLOR)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            #crop the images and resize them. Note that the images are of 2 different shape \n",
    "            #and the conv3D will throw error if the inputs in a batch have different shapes   \n",
    "            resized = cv2.resize(image, (nb_rows,nb_cols), interpolation = cv2.INTER_AREA)\n",
    "            batch_data[folder,idx] = (resized)\n",
    "            batch_data_aug[folder,idx] = (cv2.warpAffine(resized, M, (resized.shape[0], resized.shape[1])))      \n",
    "\n",
    "        batch_labels[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        batch_labels_aug[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "    \n",
    "    batch_data = np.append(batch_data, batch_data_aug, axis = 0) \n",
    "    batch_labels = np.append(batch_labels, batch_labels_aug, axis = 0) \n",
    "    return batch_data, batch_labels\n",
    "\n",
    "#Function to Validate Load Batch Images\n",
    "def val_load_batch_images(source_path, folder_list, batch_num, batch_size, t):\n",
    "    \n",
    "    batch_data,batch_labels = init_batch_data(batch_size)\n",
    "    # We will also build a agumented batch data\n",
    "    batch_data_aug,batch_labels_aug = init_batch_data(batch_size)\n",
    "\n",
    "    #create a list of image numbers you want to use for a particular video\n",
    "    img_idx = [x for x in range(0, nb_frames)] \n",
    "\n",
    "    for folder in range(batch_size): # iterate over the batch_size\n",
    "        # read all the images in the folder\n",
    "        imgs = sorted(os.listdir(source_path+'/'+ t[folder + (batch_num*batch_size)].split(';')[0])) \n",
    "        # Generate a random affine to be used in image transformation for buidling agumented data set\n",
    "        # M = get_random_affine()\n",
    "        \n",
    "        #  Iterate over the frames/images of a folder to read them in\n",
    "        for idx, item in enumerate(img_idx): \n",
    "            image = cv2.imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item], cv2.IMREAD_COLOR)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            #crop the images and resize them. Note that the images are of 2 different shape \n",
    "            #and the conv3D will throw error if the inputs in a batch have different shapes   \n",
    "            resized = cv2.resize(image, (nb_rows,nb_cols), interpolation = cv2.INTER_AREA)\n",
    "            batch_data[folder,idx] = (resized)\n",
    "            #batch_data_aug[folder,idx] = (cv2.warpAffine(resized, M, (resized.shape[0], resized.shape[1])))      \n",
    "\n",
    "        batch_labels[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        #batch_labels_aug[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "    \n",
    "    #batch_data = np.append(batch_data, batch_data_aug, axis = 0) \n",
    "    #batch_labels = np.append(batch_labels, batch_labels_aug, axis = 0) \n",
    "    return batch_data, batch_labels\n",
    "\n",
    "#The generator function for Training Data Set\n",
    "def train_generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            # you yield the batch_data and the batch_labels, remember what does yield do\n",
    "            yield train_load_batch_images(source_path, folder_list, batch, batch_size, t) \n",
    "        \n",
    "        # Code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            yield train_load_batch_images(source_path, folder_list, num_batches, batch_size, t)\n",
    "            \n",
    "#The generator function for Validation Data Set         \n",
    "def val_generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            # you yield the batch_data and the batch_labels, remember what does yield do\n",
    "            yield val_load_batch_images(source_path, folder_list, batch, batch_size, t) \n",
    "        \n",
    "        # Code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            yield val_load_batch_images(source_path, folder_list, num_batches, batch_size, t)\n",
    "            \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = './Project_data/train'\n",
    "val_path = './Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 10 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder(metaclass= abc.ABCMeta):\n",
    "    \n",
    "    def initialize_path(self,project_folder):\n",
    "        self.train_doc = np.random.permutation(open(project_folder + '/' + 'train.csv').readlines())\n",
    "        self.val_doc = np.random.permutation(open(project_folder + '/' + 'val.csv').readlines())\n",
    "        self.train_path = project_folder + '/' + 'train'\n",
    "        self.val_path =  project_folder + '/' + 'val'\n",
    "        self.num_train_sequences = len(self.train_doc)\n",
    "        self.num_val_sequences = len(self.val_doc)\n",
    "        \n",
    "    def initialize_image_properties(self,image_height=100,image_width=100):\n",
    "        self.image_height=image_height\n",
    "        self.image_width=image_width\n",
    "        self.channels=3\n",
    "        self.num_classes=5\n",
    "        self.total_frames=30\n",
    "          \n",
    "    def initialize_hyperparams(self,frames_to_sample=30,batch_size=20,num_epochs=20):\n",
    "        self.frames_to_sample=frames_to_sample\n",
    "        self.batch_size=batch_size\n",
    "        self.num_epochs=num_epochs\n",
    "        \n",
    "        \n",
    "    def generator(self,source_path, folder_list, augment=False):\n",
    "        img_idx = np.round(np.linspace(0,self.total_frames-1,self.frames_to_sample)).astype(int)\n",
    "        batch_size=self.batch_size\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(t)//batch_size\n",
    "        \n",
    "            for batch in range(num_batches): \n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,batch,batch_size,img_idx,augment)\n",
    "                yield batch_data, batch_labels \n",
    "\n",
    "            remaining_seq=len(t)%batch_size\n",
    "        \n",
    "            if (remaining_seq != 0):\n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,num_batches,batch_size,img_idx,augment,remaining_seq)\n",
    "                yield batch_data, batch_labels \n",
    "    \n",
    "    \n",
    "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
    "    \n",
    "        seq_len = remaining_seq if remaining_seq else batch_size\n",
    "    \n",
    "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
    "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
    "    \n",
    "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
    "\n",
    "        \n",
    "        for folder in range(seq_len): \n",
    "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
    "            for idx,item in enumerate(img_idx): \n",
    "                #image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                image = cv2.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item], cv2.IMREAD_COLOR)\n",
    "                #image_resized=imresize(image,(self.image_height,self.image_width,3))\n",
    "                image_resized=cv2.resize(image,(self.image_height,self.image_width),interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "\n",
    "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "            \n",
    "                if (augment):\n",
    "                    shifted = cv2.warpAffine(image, \n",
    "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
    "                                            (image.shape[1], image.shape[0]))\n",
    "                    \n",
    "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
    "                    \n",
    "                    cropped=shifted[x0:x1,y0:y1,:]\n",
    "                    \n",
    "                    #image_resized=imresize(cropped,(self.image_height,self.image_width,3))\n",
    "                    image_resized=cv2.resize(image,(self.image_height,self.image_width),interpolation = cv2.INTER_AREA)\n",
    "                    \n",
    "                    #shifted = cv2.warpAffine(image_resized, \n",
    "                    #                        np.float32([[1, 0, np.random.randint(-3,3)],[0, 1, np.random.randint(-3,3)]]), \n",
    "                    #                        (image_resized.shape[1], image_resized.shape[0]))\n",
    "            \n",
    "                    batch_data_aug[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                    batch_data_aug[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                    batch_data_aug[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "                \n",
    "            \n",
    "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "    \n",
    "        if (augment):\n",
    "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
    "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
    "\n",
    "        \n",
    "        return(batch_data,batch_labels)\n",
    "    \n",
    "    \n",
    "    def train_model(self, model, augment_data=False):\n",
    "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
    "        val_generator = self.generator(self.val_path, self.val_doc)\n",
    "\n",
    "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "        \n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
    "        callbacks_list = [checkpoint, LR]\n",
    "\n",
    "        if (self.num_train_sequences%self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
    "        else:\n",
    "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
    "\n",
    "        if (self.num_val_sequences%self.batch_size) == 0:\n",
    "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
    "        else:\n",
    "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
    "    \n",
    "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
    "                            callbacks=callbacks_list, validation_data=val_generator, \n",
    "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "        return history\n",
    "\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def define_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "nb_filters = [8,16,32,64]\n",
    "#nb_dense = [1000, 500, 5]\n",
    "nb_dense = [256, 128, 5]\n",
    "\n",
    "# Input\n",
    "input_shape=(nb_frames,nb_rows,nb_cols,nb_channel)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experimenting with batch_size =40 and num_epocs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:From <ipython-input-9-74bd90892ee0>:34: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Source path =  ./Project_data/train ; batch size = 40\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 2.1598 - categorical_accuracy: 0.2413  Source path =  ./Project_data/val ; batch size = 40\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-11-0811_04_47.013134/model-00001-2.15982-0.24133-1.56743-0.29000.h5\n",
      "17/17 [==============================] - 1268s 75s/step - loss: 2.1598 - categorical_accuracy: 0.2413 - val_loss: 1.5674 - val_categorical_accuracy: 0.2900\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.5578 - categorical_accuracy: 0.3069 \n",
      "Epoch 00002: saving model to model_init_2020-11-0811_04_47.013134/model-00002-1.55781-0.30691-1.85629-0.23333.h5\n",
      "17/17 [==============================] - 692s 41s/step - loss: 1.5578 - categorical_accuracy: 0.3069 - val_loss: 1.8563 - val_categorical_accuracy: 0.2333\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.4482 - categorical_accuracy: 0.3692 \n",
      "Epoch 00003: saving model to model_init_2020-11-0811_04_47.013134/model-00003-1.44818-0.36921-3.73004-0.13333.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "17/17 [==============================] - 594s 35s/step - loss: 1.4482 - categorical_accuracy: 0.3692 - val_loss: 3.7300 - val_categorical_accuracy: 0.1333\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2900 - categorical_accuracy: 0.4752 \n",
      "Epoch 00004: saving model to model_init_2020-11-0811_04_47.013134/model-00004-1.28999-0.47523-2.83063-0.30000.h5\n",
      "17/17 [==============================] - 528s 31s/step - loss: 1.2900 - categorical_accuracy: 0.4752 - val_loss: 2.8306 - val_categorical_accuracy: 0.3000\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2753 - categorical_accuracy: 0.4712 \n",
      "Epoch 00005: saving model to model_init_2020-11-0811_04_47.013134/model-00005-1.27530-0.47125-2.13278-0.23333.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "17/17 [==============================] - 511s 30s/step - loss: 1.2753 - categorical_accuracy: 0.4712 - val_loss: 2.1328 - val_categorical_accuracy: 0.2333\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.1328 - categorical_accuracy: 0.5381 \n",
      "Epoch 00006: saving model to model_init_2020-11-0811_04_47.013134/model-00006-1.13275-0.53806-1.78556-0.23333.h5\n",
      "17/17 [==============================] - 473s 28s/step - loss: 1.1328 - categorical_accuracy: 0.5381 - val_loss: 1.7856 - val_categorical_accuracy: 0.2333\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0710 - categorical_accuracy: 0.5554 \n",
      "Epoch 00007: saving model to model_init_2020-11-0811_04_47.013134/model-00007-1.07104-0.55536-1.65400-0.28333.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "17/17 [==============================] - 474s 28s/step - loss: 1.0710 - categorical_accuracy: 0.5554 - val_loss: 1.6540 - val_categorical_accuracy: 0.2833\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0224 - categorical_accuracy: 0.5917 \n",
      "Epoch 00008: saving model to model_init_2020-11-0811_04_47.013134/model-00008-1.02238-0.59170-1.41787-0.40000.h5\n",
      "17/17 [==============================] - 475s 28s/step - loss: 1.0224 - categorical_accuracy: 0.5917 - val_loss: 1.4179 - val_categorical_accuracy: 0.4000\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9396 - categorical_accuracy: 0.6228 \n",
      "Epoch 00009: saving model to model_init_2020-11-0811_04_47.013134/model-00009-0.93963-0.62284-1.41623-0.45000.h5\n",
      "17/17 [==============================] - 473s 28s/step - loss: 0.9396 - categorical_accuracy: 0.6228 - val_loss: 1.4162 - val_categorical_accuracy: 0.4500\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9887 - categorical_accuracy: 0.6211 \n",
      "Epoch 00010: saving model to model_init_2020-11-0811_04_47.013134/model-00010-0.98871-0.62111-1.23277-0.41667.h5\n",
      "17/17 [==============================] - 474s 28s/step - loss: 0.9887 - categorical_accuracy: 0.6211 - val_loss: 1.2328 - val_categorical_accuracy: 0.4167\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9489 - categorical_accuracy: 0.6194 \n",
      "Epoch 00011: saving model to model_init_2020-11-0811_04_47.013134/model-00011-0.94894-0.61938-1.08724-0.55000.h5\n",
      "17/17 [==============================] - 473s 28s/step - loss: 0.9489 - categorical_accuracy: 0.6194 - val_loss: 1.0872 - val_categorical_accuracy: 0.5500\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8603 - categorical_accuracy: 0.6730 \n",
      "Epoch 00012: saving model to model_init_2020-11-0811_04_47.013134/model-00012-0.86031-0.67301-1.02445-0.55000.h5\n",
      "17/17 [==============================] - 474s 28s/step - loss: 0.8603 - categorical_accuracy: 0.6730 - val_loss: 1.0245 - val_categorical_accuracy: 0.5500\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8937 - categorical_accuracy: 0.6557 \n",
      "Epoch 00013: saving model to model_init_2020-11-0811_04_47.013134/model-00013-0.89371-0.65571-0.85334-0.73333.h5\n",
      "17/17 [==============================] - 473s 28s/step - loss: 0.8937 - categorical_accuracy: 0.6557 - val_loss: 0.8533 - val_categorical_accuracy: 0.7333\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8186 - categorical_accuracy: 0.6938 \n",
      "Epoch 00014: saving model to model_init_2020-11-0811_04_47.013134/model-00014-0.81859-0.69377-1.04223-0.58333.h5\n",
      "17/17 [==============================] - 473s 28s/step - loss: 0.8186 - categorical_accuracy: 0.6938 - val_loss: 1.0422 - val_categorical_accuracy: 0.5833\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7673 - categorical_accuracy: 0.7215 \n",
      "Epoch 00015: saving model to model_init_2020-11-0811_04_47.013134/model-00015-0.76734-0.72145-0.86311-0.70000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "17/17 [==============================] - 475s 28s/step - loss: 0.7673 - categorical_accuracy: 0.7215 - val_loss: 0.8631 - val_categorical_accuracy: 0.7000\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8820 - categorical_accuracy: 0.6505 \n",
      "Epoch 00016: saving model to model_init_2020-11-0811_04_47.013134/model-00016-0.88198-0.65052-0.94422-0.65000.h5\n",
      "17/17 [==============================] - 473s 28s/step - loss: 0.8820 - categorical_accuracy: 0.6505 - val_loss: 0.9442 - val_categorical_accuracy: 0.6500\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7218 - categorical_accuracy: 0.7388 \n",
      "Epoch 00017: saving model to model_init_2020-11-0811_04_47.013134/model-00017-0.72175-0.73875-0.88224-0.75000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "17/17 [==============================] - 472s 28s/step - loss: 0.7218 - categorical_accuracy: 0.7388 - val_loss: 0.8822 - val_categorical_accuracy: 0.7500\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8217 - categorical_accuracy: 0.6696 \n",
      "Epoch 00018: saving model to model_init_2020-11-0811_04_47.013134/model-00018-0.82173-0.66955-0.84750-0.70000.h5\n",
      "17/17 [==============================] - 474s 28s/step - loss: 0.8217 - categorical_accuracy: 0.6696 - val_loss: 0.8475 - val_categorical_accuracy: 0.7000\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7548 - categorical_accuracy: 0.7007 \n",
      "Epoch 00019: saving model to model_init_2020-11-0811_04_47.013134/model-00019-0.75476-0.70069-0.80808-0.73333.h5\n",
      "17/17 [==============================] - 473s 28s/step - loss: 0.7548 - categorical_accuracy: 0.7007 - val_loss: 0.8081 - val_categorical_accuracy: 0.7333\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7716 - categorical_accuracy: 0.7232 \n",
      "Epoch 00020: saving model to model_init_2020-11-0811_04_47.013134/model-00020-0.77159-0.72318-0.84043-0.71667.h5\n",
      "17/17 [==============================] - 486s 29s/step - loss: 0.7716 - categorical_accuracy: 0.7232 - val_loss: 0.8404 - val_categorical_accuracy: 0.7167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7270 - categorical_accuracy: 0.7439 \n",
      "Epoch 00021: saving model to model_init_2020-11-0811_04_47.013134/model-00021-0.72698-0.74394-0.87686-0.66667.h5\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "17/17 [==============================] - 479s 28s/step - loss: 0.7270 - categorical_accuracy: 0.7439 - val_loss: 0.8769 - val_categorical_accuracy: 0.6667\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7175 - categorical_accuracy: 0.7405 \n",
      "Epoch 00022: saving model to model_init_2020-11-0811_04_47.013134/model-00022-0.71748-0.74048-0.90798-0.65000.h5\n",
      "17/17 [==============================] - 482s 28s/step - loss: 0.7175 - categorical_accuracy: 0.7405 - val_loss: 0.9080 - val_categorical_accuracy: 0.6500\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7500 - categorical_accuracy: 0.7180 \n",
      "Epoch 00023: saving model to model_init_2020-11-0811_04_47.013134/model-00023-0.74998-0.71799-0.97677-0.61667.h5\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "17/17 [==============================] - 485s 29s/step - loss: 0.7500 - categorical_accuracy: 0.7180 - val_loss: 0.9768 - val_categorical_accuracy: 0.6167\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7706 - categorical_accuracy: 0.7007 \n",
      "Epoch 00024: saving model to model_init_2020-11-0811_04_47.013134/model-00024-0.77058-0.70069-0.83825-0.71667.h5\n",
      "17/17 [==============================] - 479s 28s/step - loss: 0.7706 - categorical_accuracy: 0.7007 - val_loss: 0.8383 - val_categorical_accuracy: 0.7167\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7349 - categorical_accuracy: 0.7526 \n",
      "Epoch 00025: saving model to model_init_2020-11-0811_04_47.013134/model-00025-0.73486-0.75260-0.73445-0.76667.h5\n",
      "17/17 [==============================] - 484s 28s/step - loss: 0.7349 - categorical_accuracy: 0.7526 - val_loss: 0.7345 - val_categorical_accuracy: 0.7667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5c652b2e50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 40\n",
    "num_epochs = 25\n",
    "\n",
    "train_generator = train_generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_generator(val_path, val_doc, batch_size)\n",
    "\n",
    "\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]\n",
    "\n",
    "\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "    \n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increasing Batch Size=90 and Epochs to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.8075 - categorical_accuracy: 0.6801 \n",
      "Epoch 00001: saving model to model_init_2020-11-0811_04_47.013134/model-00001-0.80754-0.68015-0.88577-0.72500.h5\n",
      "8/8 [==============================] - 231s 29s/step - loss: 0.8075 - categorical_accuracy: 0.6801 - val_loss: 0.8858 - val_categorical_accuracy: 0.7250\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7674 - categorical_accuracy: 0.7096 \n",
      "Epoch 00002: saving model to model_init_2020-11-0811_04_47.013134/model-00002-0.76738-0.70956-0.94847-0.65000.h5\n",
      "8/8 [==============================] - 228s 28s/step - loss: 0.7674 - categorical_accuracy: 0.7096 - val_loss: 0.9485 - val_categorical_accuracy: 0.6500\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7453 - categorical_accuracy: 0.7206 \n",
      "Epoch 00003: saving model to model_init_2020-11-0811_04_47.013134/model-00003-0.74528-0.72059-0.75565-0.75000.h5\n",
      "8/8 [==============================] - 238s 30s/step - loss: 0.7453 - categorical_accuracy: 0.7206 - val_loss: 0.7556 - val_categorical_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6995 - categorical_accuracy: 0.7206 \n",
      "Epoch 00004: saving model to model_init_2020-11-0811_04_47.013134/model-00004-0.69952-0.72059-0.80910-0.72500.h5\n",
      "8/8 [==============================] - 234s 29s/step - loss: 0.6995 - categorical_accuracy: 0.7206 - val_loss: 0.8091 - val_categorical_accuracy: 0.7250\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7664 - categorical_accuracy: 0.7426 \n",
      "Epoch 00005: saving model to model_init_2020-11-0811_04_47.013134/model-00005-0.76638-0.74265-0.88826-0.67500.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "8/8 [==============================] - 232s 29s/step - loss: 0.7664 - categorical_accuracy: 0.7426 - val_loss: 0.8883 - val_categorical_accuracy: 0.6750\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6379 - categorical_accuracy: 0.7721 \n",
      "Epoch 00006: saving model to model_init_2020-11-0811_04_47.013134/model-00006-0.63787-0.77206-0.89874-0.67500.h5\n",
      "8/8 [==============================] - 215s 27s/step - loss: 0.6379 - categorical_accuracy: 0.7721 - val_loss: 0.8987 - val_categorical_accuracy: 0.6750\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7834 - categorical_accuracy: 0.6875 \n",
      "Epoch 00007: saving model to model_init_2020-11-0811_04_47.013134/model-00007-0.78341-0.68750-0.72970-0.72500.h5\n",
      "8/8 [==============================] - 213s 27s/step - loss: 0.7834 - categorical_accuracy: 0.6875 - val_loss: 0.7297 - val_categorical_accuracy: 0.7250\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6836 - categorical_accuracy: 0.7463 \n",
      "Epoch 00008: saving model to model_init_2020-11-0811_04_47.013134/model-00008-0.68365-0.74632-0.91671-0.72500.h5\n",
      "8/8 [==============================] - 211s 26s/step - loss: 0.6836 - categorical_accuracy: 0.7463 - val_loss: 0.9167 - val_categorical_accuracy: 0.7250\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7776 - categorical_accuracy: 0.6912 \n",
      "Epoch 00009: saving model to model_init_2020-11-0811_04_47.013134/model-00009-0.77759-0.69118-0.78886-0.72500.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "8/8 [==============================] - 212s 26s/step - loss: 0.7776 - categorical_accuracy: 0.6912 - val_loss: 0.7889 - val_categorical_accuracy: 0.7250\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6846 - categorical_accuracy: 0.7500 \n",
      "Epoch 00010: saving model to model_init_2020-11-0811_04_47.013134/model-00010-0.68463-0.75000-0.96989-0.60000.h5\n",
      "8/8 [==============================] - 212s 26s/step - loss: 0.6846 - categorical_accuracy: 0.7500 - val_loss: 0.9699 - val_categorical_accuracy: 0.6000\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7369 - categorical_accuracy: 0.7169 \n",
      "Epoch 00011: saving model to model_init_2020-11-0811_04_47.013134/model-00011-0.73691-0.71691-0.77197-0.75000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "8/8 [==============================] - 212s 26s/step - loss: 0.7369 - categorical_accuracy: 0.7169 - val_loss: 0.7720 - val_categorical_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7535 - categorical_accuracy: 0.7463 \n",
      "Epoch 00012: saving model to model_init_2020-11-0811_04_47.013134/model-00012-0.75352-0.74632-0.94463-0.55000.h5\n",
      "8/8 [==============================] - 212s 26s/step - loss: 0.7535 - categorical_accuracy: 0.7463 - val_loss: 0.9446 - val_categorical_accuracy: 0.5500\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7098 - categorical_accuracy: 0.7353 \n",
      "Epoch 00013: saving model to model_init_2020-11-0811_04_47.013134/model-00013-0.70976-0.73529-0.74096-0.80000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "8/8 [==============================] - 212s 26s/step - loss: 0.7098 - categorical_accuracy: 0.7353 - val_loss: 0.7410 - val_categorical_accuracy: 0.8000\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7667 - categorical_accuracy: 0.6581 \n",
      "Epoch 00014: saving model to model_init_2020-11-0811_04_47.013134/model-00014-0.76667-0.65809-0.82054-0.70000.h5\n",
      "8/8 [==============================] - 211s 26s/step - loss: 0.7667 - categorical_accuracy: 0.6581 - val_loss: 0.8205 - val_categorical_accuracy: 0.7000\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7826 - categorical_accuracy: 0.7169 \n",
      "Epoch 00015: saving model to model_init_2020-11-0811_04_47.013134/model-00015-0.78258-0.71691-0.78224-0.77500.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "8/8 [==============================] - 211s 26s/step - loss: 0.7826 - categorical_accuracy: 0.7169 - val_loss: 0.7822 - val_categorical_accuracy: 0.7750\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7527 - categorical_accuracy: 0.7279 \n",
      "Epoch 00016: saving model to model_init_2020-11-0811_04_47.013134/model-00016-0.75265-0.72794-0.85629-0.75000.h5\n",
      "8/8 [==============================] - 212s 27s/step - loss: 0.7527 - categorical_accuracy: 0.7279 - val_loss: 0.8563 - val_categorical_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6889 - categorical_accuracy: 0.7169 \n",
      "Epoch 00017: saving model to model_init_2020-11-0811_04_47.013134/model-00017-0.68892-0.71691-0.84734-0.80000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "8/8 [==============================] - 218s 27s/step - loss: 0.6889 - categorical_accuracy: 0.7169 - val_loss: 0.8473 - val_categorical_accuracy: 0.8000\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6554 - categorical_accuracy: 0.7684 \n",
      "Epoch 00018: saving model to model_init_2020-11-0811_04_47.013134/model-00018-0.65537-0.76838-0.84827-0.65000.h5\n",
      "8/8 [==============================] - 224s 28s/step - loss: 0.6554 - categorical_accuracy: 0.7684 - val_loss: 0.8483 - val_categorical_accuracy: 0.6500\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7987 - categorical_accuracy: 0.6949 \n",
      "Epoch 00019: saving model to model_init_2020-11-0811_04_47.013134/model-00019-0.79872-0.69485-0.94272-0.67500.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "8/8 [==============================] - 213s 27s/step - loss: 0.7987 - categorical_accuracy: 0.6949 - val_loss: 0.9427 - val_categorical_accuracy: 0.6750\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7422 - categorical_accuracy: 0.7610 \n",
      "Epoch 00020: saving model to model_init_2020-11-0811_04_47.013134/model-00020-0.74216-0.76103-0.72266-0.77500.h5\n",
      "8/8 [==============================] - 211s 26s/step - loss: 0.7422 - categorical_accuracy: 0.7610 - val_loss: 0.7227 - val_categorical_accuracy: 0.7750\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6649 - categorical_accuracy: 0.7684 \n",
      "Epoch 00021: saving model to model_init_2020-11-0811_04_47.013134/model-00021-0.66487-0.76838-0.91747-0.65000.h5\n",
      "8/8 [==============================] - 211s 26s/step - loss: 0.6649 - categorical_accuracy: 0.7684 - val_loss: 0.9175 - val_categorical_accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7067 - categorical_accuracy: 0.7132 \n",
      "Epoch 00022: saving model to model_init_2020-11-0811_04_47.013134/model-00022-0.70665-0.71324-0.82174-0.77500.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "8/8 [==============================] - 211s 26s/step - loss: 0.7067 - categorical_accuracy: 0.7132 - val_loss: 0.8217 - val_categorical_accuracy: 0.7750\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7442 - categorical_accuracy: 0.7353 \n",
      "Epoch 00023: saving model to model_init_2020-11-0811_04_47.013134/model-00023-0.74416-0.73529-0.78866-0.65000.h5\n",
      "8/8 [==============================] - 221s 28s/step - loss: 0.7442 - categorical_accuracy: 0.7353 - val_loss: 0.7887 - val_categorical_accuracy: 0.6500\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7777 - categorical_accuracy: 0.7059 \n",
      "Epoch 00024: saving model to model_init_2020-11-0811_04_47.013134/model-00024-0.77773-0.70588-0.72411-0.85000.h5\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "8/8 [==============================] - 226s 28s/step - loss: 0.7777 - categorical_accuracy: 0.7059 - val_loss: 0.7241 - val_categorical_accuracy: 0.8500\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7808 - categorical_accuracy: 0.6838 \n",
      "Epoch 00025: saving model to model_init_2020-11-0811_04_47.013134/model-00025-0.78076-0.68382-0.66410-0.80000.h5\n",
      "8/8 [==============================] - 225s 28s/step - loss: 0.7808 - categorical_accuracy: 0.6838 - val_loss: 0.6641 - val_categorical_accuracy: 0.8000\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7923 - categorical_accuracy: 0.6875 \n",
      "Epoch 00026: saving model to model_init_2020-11-0811_04_47.013134/model-00026-0.79233-0.68750-0.98622-0.62500.h5\n",
      "8/8 [==============================] - 226s 28s/step - loss: 0.7923 - categorical_accuracy: 0.6875 - val_loss: 0.9862 - val_categorical_accuracy: 0.6250\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7716 - categorical_accuracy: 0.6985 \n",
      "Epoch 00027: saving model to model_init_2020-11-0811_04_47.013134/model-00027-0.77164-0.69853-0.70840-0.77500.h5\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "8/8 [==============================] - 223s 28s/step - loss: 0.7716 - categorical_accuracy: 0.6985 - val_loss: 0.7084 - val_categorical_accuracy: 0.7750\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6231 - categorical_accuracy: 0.8015 \n",
      "Epoch 00028: saving model to model_init_2020-11-0811_04_47.013134/model-00028-0.62310-0.80147-0.93870-0.70000.h5\n",
      "8/8 [==============================] - 211s 26s/step - loss: 0.6231 - categorical_accuracy: 0.8015 - val_loss: 0.9387 - val_categorical_accuracy: 0.7000\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7896 - categorical_accuracy: 0.6949 \n",
      "Epoch 00029: saving model to model_init_2020-11-0811_04_47.013134/model-00029-0.78959-0.69485-0.72786-0.77500.h5\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "8/8 [==============================] - 211s 26s/step - loss: 0.7896 - categorical_accuracy: 0.6949 - val_loss: 0.7279 - val_categorical_accuracy: 0.7750\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7167 - categorical_accuracy: 0.7647 \n",
      "Epoch 00030: saving model to model_init_2020-11-0811_04_47.013134/model-00030-0.71671-0.76471-0.78127-0.72500.h5\n",
      "8/8 [==============================] - 210s 26s/step - loss: 0.7167 - categorical_accuracy: 0.7647 - val_loss: 0.7813 - val_categorical_accuracy: 0.7250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5c653ece50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 90\n",
    "num_epochs = 30\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "    \n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
    "                                  input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(256, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "  \n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "        model.add(LSTM(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 18, 120, 120, 16)  448       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 18, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 18, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 18, 60, 60, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 18, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 18, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 18, 30, 30, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 18, 30, 30, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 18, 15, 15, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 18, 15, 15, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 18, 15, 15, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 18, 7, 7, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 18, 7, 7, 256)     295168    \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 18, 7, 7, 256)     1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 18, 3, 3, 256)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 18, 2304)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               1245696   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,657,445\n",
      "Trainable params: 1,656,453\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_cnn1=CNN_LSTM()\n",
    "rnn_cnn1.initialize_path(project_folder)\n",
    "rnn_cnn1.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn1.initialize_hyperparams(frames_to_sample=18,batch_size=50,num_epochs=30)\n",
    "rnn_cnn1_model=rnn_cnn1.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 1657445\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:From <ipython-input-8-f23cee5fe61d>:125: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.4110 - categorical_accuracy: 0.3899 \n",
      "Epoch 00001: saving model to model_init_2020-11-0818_31_09.136730/model-00001-1.41105-0.38989-1.61809-0.30000.h5\n",
      "14/14 [==============================] - 332s 24s/step - loss: 1.4110 - categorical_accuracy: 0.3899 - val_loss: 1.6181 - val_categorical_accuracy: 0.3000\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.1261 - categorical_accuracy: 0.5339 \n",
      "Epoch 00002: saving model to model_init_2020-11-0818_31_09.136730/model-00002-1.12613-0.53394-1.89550-0.20000.h5\n",
      "14/14 [==============================] - 323s 23s/step - loss: 1.1261 - categorical_accuracy: 0.5339 - val_loss: 1.8955 - val_categorical_accuracy: 0.2000\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9634 - categorical_accuracy: 0.6229 \n",
      "Epoch 00003: saving model to model_init_2020-11-0818_31_09.136730/model-00003-0.96337-0.62293-2.06779-0.24000.h5\n",
      "14/14 [==============================] - 322s 23s/step - loss: 0.9634 - categorical_accuracy: 0.6229 - val_loss: 2.0678 - val_categorical_accuracy: 0.2400\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7789 - categorical_accuracy: 0.6968 \n",
      "Epoch 00004: saving model to model_init_2020-11-0818_31_09.136730/model-00004-0.77887-0.69683-2.33261-0.21000.h5\n",
      "14/14 [==============================] - 322s 23s/step - loss: 0.7789 - categorical_accuracy: 0.6968 - val_loss: 2.3326 - val_categorical_accuracy: 0.2100\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6930 - categorical_accuracy: 0.7489 \n",
      "Epoch 00005: saving model to model_init_2020-11-0818_31_09.136730/model-00005-0.69297-0.74887-2.80994-0.21000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "14/14 [==============================] - 327s 23s/step - loss: 0.6930 - categorical_accuracy: 0.7489 - val_loss: 2.8099 - val_categorical_accuracy: 0.2100\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.5256 - categorical_accuracy: 0.8205 \n",
      "Epoch 00006: saving model to model_init_2020-11-0818_31_09.136730/model-00006-0.52560-0.82051-2.74710-0.27000.h5\n",
      "14/14 [==============================] - 322s 23s/step - loss: 0.5256 - categorical_accuracy: 0.8205 - val_loss: 2.7471 - val_categorical_accuracy: 0.2700\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4610 - categorical_accuracy: 0.8446 \n",
      "Epoch 00007: saving model to model_init_2020-11-0818_31_09.136730/model-00007-0.46099-0.84465-2.82530-0.21000.h5\n",
      "14/14 [==============================] - 323s 23s/step - loss: 0.4610 - categorical_accuracy: 0.8446 - val_loss: 2.8253 - val_categorical_accuracy: 0.2100\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4031 - categorical_accuracy: 0.8567 \n",
      "Epoch 00008: saving model to model_init_2020-11-0818_31_09.136730/model-00008-0.40312-0.85671-2.84933-0.20000.h5\n",
      "14/14 [==============================] - 344s 25s/step - loss: 0.4031 - categorical_accuracy: 0.8567 - val_loss: 2.8493 - val_categorical_accuracy: 0.2000\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3525 - categorical_accuracy: 0.8899 \n",
      "Epoch 00009: saving model to model_init_2020-11-0818_31_09.136730/model-00009-0.35252-0.88989-2.82342-0.21000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "14/14 [==============================] - 329s 24s/step - loss: 0.3525 - categorical_accuracy: 0.8899 - val_loss: 2.8234 - val_categorical_accuracy: 0.2100\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2982 - categorical_accuracy: 0.9186 \n",
      "Epoch 00010: saving model to model_init_2020-11-0818_31_09.136730/model-00010-0.29819-0.91855-2.84993-0.18000.h5\n",
      "14/14 [==============================] - 327s 23s/step - loss: 0.2982 - categorical_accuracy: 0.9186 - val_loss: 2.8499 - val_categorical_accuracy: 0.1800\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2674 - categorical_accuracy: 0.9299 \n",
      "Epoch 00011: saving model to model_init_2020-11-0818_31_09.136730/model-00011-0.26742-0.92986-2.87628-0.21000.h5\n",
      "14/14 [==============================] - 324s 23s/step - loss: 0.2674 - categorical_accuracy: 0.9299 - val_loss: 2.8763 - val_categorical_accuracy: 0.2100\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2673 - categorical_accuracy: 0.9268 \n",
      "Epoch 00012: saving model to model_init_2020-11-0818_31_09.136730/model-00012-0.26734-0.92685-2.93802-0.22000.h5\n",
      "14/14 [==============================] - 326s 23s/step - loss: 0.2673 - categorical_accuracy: 0.9268 - val_loss: 2.9380 - val_categorical_accuracy: 0.2200\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2568 - categorical_accuracy: 0.9314 \n",
      "Epoch 00013: saving model to model_init_2020-11-0818_31_09.136730/model-00013-0.25678-0.93137-2.87128-0.21000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "14/14 [==============================] - 325s 23s/step - loss: 0.2568 - categorical_accuracy: 0.9314 - val_loss: 2.8713 - val_categorical_accuracy: 0.2100\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2356 - categorical_accuracy: 0.9449 \n",
      "Epoch 00014: saving model to model_init_2020-11-0818_31_09.136730/model-00014-0.23561-0.94495-2.92481-0.19000.h5\n",
      "14/14 [==============================] - 330s 24s/step - loss: 0.2356 - categorical_accuracy: 0.9449 - val_loss: 2.9248 - val_categorical_accuracy: 0.1900\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2493 - categorical_accuracy: 0.9344 \n",
      "Epoch 00015: saving model to model_init_2020-11-0818_31_09.136730/model-00015-0.24926-0.93439-2.89307-0.21000.h5\n",
      "14/14 [==============================] - 324s 23s/step - loss: 0.2493 - categorical_accuracy: 0.9344 - val_loss: 2.8931 - val_categorical_accuracy: 0.2100\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2517 - categorical_accuracy: 0.9291 \n",
      "Epoch 00016: saving model to model_init_2020-11-0818_31_09.136730/model-00016-0.25165-0.92911-2.70049-0.22000.h5\n",
      "14/14 [==============================] - 340s 24s/step - loss: 0.2517 - categorical_accuracy: 0.9291 - val_loss: 2.7005 - val_categorical_accuracy: 0.2200\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2413 - categorical_accuracy: 0.9404 \n",
      "Epoch 00017: saving model to model_init_2020-11-0818_31_09.136730/model-00017-0.24128-0.94042-2.93672-0.21000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "14/14 [==============================] - 327s 23s/step - loss: 0.2413 - categorical_accuracy: 0.9404 - val_loss: 2.9367 - val_categorical_accuracy: 0.2100\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2502 - categorical_accuracy: 0.9367 \n",
      "Epoch 00018: saving model to model_init_2020-11-0818_31_09.136730/model-00018-0.25019-0.93665-2.85902-0.24000.h5\n",
      "14/14 [==============================] - 334s 24s/step - loss: 0.2502 - categorical_accuracy: 0.9367 - val_loss: 2.8590 - val_categorical_accuracy: 0.2400\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2263 - categorical_accuracy: 0.9465 \n",
      "Epoch 00019: saving model to model_init_2020-11-0818_31_09.136730/model-00019-0.22635-0.94646-2.91859-0.21000.h5\n",
      "14/14 [==============================] - 328s 23s/step - loss: 0.2263 - categorical_accuracy: 0.9465 - val_loss: 2.9186 - val_categorical_accuracy: 0.2100\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2308 - categorical_accuracy: 0.9427 \n",
      "Epoch 00020: saving model to model_init_2020-11-0818_31_09.136730/model-00020-0.23082-0.94268-2.88569-0.25000.h5\n",
      "14/14 [==============================] - 322s 23s/step - loss: 0.2308 - categorical_accuracy: 0.9427 - val_loss: 2.8857 - val_categorical_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2361 - categorical_accuracy: 0.9449 \n",
      "Epoch 00021: saving model to model_init_2020-11-0818_31_09.136730/model-00021-0.23612-0.94495-2.84887-0.22000.h5\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "14/14 [==============================] - 322s 23s/step - loss: 0.2361 - categorical_accuracy: 0.9449 - val_loss: 2.8489 - val_categorical_accuracy: 0.2200\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2304 - categorical_accuracy: 0.9442 \n",
      "Epoch 00022: saving model to model_init_2020-11-0818_31_09.136730/model-00022-0.23040-0.94419-2.98801-0.19000.h5\n",
      "14/14 [==============================] - 323s 23s/step - loss: 0.2304 - categorical_accuracy: 0.9442 - val_loss: 2.9880 - val_categorical_accuracy: 0.1900\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2224 - categorical_accuracy: 0.9427 \n",
      "Epoch 00023: saving model to model_init_2020-11-0818_31_09.136730/model-00023-0.22237-0.94268-2.76428-0.24000.h5\n",
      "14/14 [==============================] - 328s 23s/step - loss: 0.2224 - categorical_accuracy: 0.9427 - val_loss: 2.7643 - val_categorical_accuracy: 0.2400\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2449 - categorical_accuracy: 0.9404 \n",
      "Epoch 00024: saving model to model_init_2020-11-0818_31_09.136730/model-00024-0.24488-0.94042-2.83806-0.22000.h5\n",
      "14/14 [==============================] - 322s 23s/step - loss: 0.2449 - categorical_accuracy: 0.9404 - val_loss: 2.8381 - val_categorical_accuracy: 0.2200\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2273 - categorical_accuracy: 0.9465 \n",
      "Epoch 00025: saving model to model_init_2020-11-0818_31_09.136730/model-00025-0.22729-0.94646-2.70034-0.27000.h5\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "14/14 [==============================] - 322s 23s/step - loss: 0.2273 - categorical_accuracy: 0.9465 - val_loss: 2.7003 - val_categorical_accuracy: 0.2700\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2379 - categorical_accuracy: 0.9404 \n",
      "Epoch 00026: saving model to model_init_2020-11-0818_31_09.136730/model-00026-0.23791-0.94042-2.67763-0.30000.h5\n",
      "14/14 [==============================] - 323s 23s/step - loss: 0.2379 - categorical_accuracy: 0.9404 - val_loss: 2.6776 - val_categorical_accuracy: 0.3000\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2413 - categorical_accuracy: 0.9404 \n",
      "Epoch 00027: saving model to model_init_2020-11-0818_31_09.136730/model-00027-0.24132-0.94042-2.64345-0.30000.h5\n",
      "14/14 [==============================] - 323s 23s/step - loss: 0.2413 - categorical_accuracy: 0.9404 - val_loss: 2.6435 - val_categorical_accuracy: 0.3000\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2309 - categorical_accuracy: 0.9480 \n",
      "Epoch 00028: saving model to model_init_2020-11-0818_31_09.136730/model-00028-0.23090-0.94796-2.61430-0.32000.h5\n",
      "14/14 [==============================] - 323s 23s/step - loss: 0.2309 - categorical_accuracy: 0.9480 - val_loss: 2.6143 - val_categorical_accuracy: 0.3200\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2261 - categorical_accuracy: 0.9465 \n",
      "Epoch 00029: saving model to model_init_2020-11-0818_31_09.136730/model-00029-0.22605-0.94646-2.48344-0.34000.h5\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "14/14 [==============================] - 335s 24s/step - loss: 0.2261 - categorical_accuracy: 0.9465 - val_loss: 2.4834 - val_categorical_accuracy: 0.3400\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2331 - categorical_accuracy: 0.9465 \n",
      "Epoch 00030: saving model to model_init_2020-11-0818_31_09.136730/model-00030-0.23310-0.94646-2.46493-0.40000.h5\n",
      "14/14 [==============================] - 329s 23s/step - loss: 0.2331 - categorical_accuracy: 0.9465 - val_loss: 2.4649 - val_categorical_accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", rnn_cnn1_model.count_params())\n",
    "history_model9=rnn_cnn1.train_model(rnn_cnn1_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increasing Image size and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_16 (TimeDis (None, 18, 120, 120, 16)  448       \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 18, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 18, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 18, 60, 60, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 18, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 18, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_22 (TimeDis (None, 18, 30, 30, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 18, 30, 30, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 18, 15, 15, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 18, 15, 15, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 18, 15, 15, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 18, 7, 7, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 18, 7, 7, 256)     295168    \n",
      "_________________________________________________________________\n",
      "time_distributed_29 (TimeDis (None, 18, 7, 7, 256)     1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_30 (TimeDis (None, 18, 3, 3, 256)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 18, 2304)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               1245696   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,657,445\n",
      "Trainable params: 1,656,453\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_lstm1=CNN_LSTM()\n",
    "cnn_lstm1.initialize_path(project_folder)\n",
    "cnn_lstm1.initialize_image_properties(image_height=160,image_width=160)\n",
    "cnn_lstm1.initialize_hyperparams(frames_to_sample=18,batch_size=60,num_epochs=30)\n",
    "cnn_lstm1_model=rnn_cnn1.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "cnn_lstm1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 1657445\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.4692 - categorical_accuracy: 0.3620 \n",
      "Epoch 00001: saving model to model_init_2020-11-0821_27_41.262860/model-00001-1.46916-0.36199-1.61130-0.28000.h5\n",
      "14/14 [==============================] - 338s 24s/step - loss: 1.4692 - categorical_accuracy: 0.3620 - val_loss: 1.6113 - val_categorical_accuracy: 0.2800\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.1942 - categorical_accuracy: 0.4970 \n",
      "Epoch 00002: saving model to model_init_2020-11-0821_27_41.262860/model-00002-1.19420-0.49698-1.66770-0.24000.h5\n",
      "14/14 [==============================] - 340s 24s/step - loss: 1.1942 - categorical_accuracy: 0.4970 - val_loss: 1.6677 - val_categorical_accuracy: 0.2400\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0286 - categorical_accuracy: 0.5814 \n",
      "Epoch 00003: saving model to model_init_2020-11-0821_27_41.262860/model-00003-1.02862-0.58145-1.98773-0.21000.h5\n",
      "14/14 [==============================] - 364s 26s/step - loss: 1.0286 - categorical_accuracy: 0.5814 - val_loss: 1.9877 - val_categorical_accuracy: 0.2100\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9043 - categorical_accuracy: 0.6531 \n",
      "Epoch 00004: saving model to model_init_2020-11-0821_27_41.262860/model-00004-0.90433-0.65309-1.98205-0.20000.h5\n",
      "14/14 [==============================] - 337s 24s/step - loss: 0.9043 - categorical_accuracy: 0.6531 - val_loss: 1.9821 - val_categorical_accuracy: 0.2000\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8151 - categorical_accuracy: 0.6848 \n",
      "Epoch 00005: saving model to model_init_2020-11-0821_27_41.262860/model-00005-0.81512-0.68477-2.18509-0.21000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "14/14 [==============================] - 337s 24s/step - loss: 0.8151 - categorical_accuracy: 0.6848 - val_loss: 2.1851 - val_categorical_accuracy: 0.2100\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7218 - categorical_accuracy: 0.7300 \n",
      "Epoch 00006: saving model to model_init_2020-11-0821_27_41.262860/model-00006-0.72181-0.73002-2.23398-0.23000.h5\n",
      "14/14 [==============================] - 336s 24s/step - loss: 0.7218 - categorical_accuracy: 0.7300 - val_loss: 2.2340 - val_categorical_accuracy: 0.2300\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.5886 - categorical_accuracy: 0.7949 \n",
      "Epoch 00007: saving model to model_init_2020-11-0821_27_41.262860/model-00007-0.58863-0.79487-2.34237-0.22000.h5\n",
      "14/14 [==============================] - 337s 24s/step - loss: 0.5886 - categorical_accuracy: 0.7949 - val_loss: 2.3424 - val_categorical_accuracy: 0.2200\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.5459 - categorical_accuracy: 0.8250 \n",
      "Epoch 00008: saving model to model_init_2020-11-0821_27_41.262860/model-00008-0.54593-0.82504-2.46967-0.18000.h5\n",
      "14/14 [==============================] - 343s 24s/step - loss: 0.5459 - categorical_accuracy: 0.8250 - val_loss: 2.4697 - val_categorical_accuracy: 0.1800\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4552 - categorical_accuracy: 0.8552 \n",
      "Epoch 00009: saving model to model_init_2020-11-0821_27_41.262860/model-00009-0.45516-0.85520-2.31216-0.16000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "14/14 [==============================] - 336s 24s/step - loss: 0.4552 - categorical_accuracy: 0.8552 - val_loss: 2.3122 - val_categorical_accuracy: 0.1600\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4191 - categorical_accuracy: 0.8725 \n",
      "Epoch 00010: saving model to model_init_2020-11-0821_27_41.262860/model-00010-0.41913-0.87255-2.15083-0.14000.h5\n",
      "14/14 [==============================] - 335s 24s/step - loss: 0.4191 - categorical_accuracy: 0.8725 - val_loss: 2.1508 - val_categorical_accuracy: 0.1400\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3761 - categorical_accuracy: 0.8899 \n",
      "Epoch 00011: saving model to model_init_2020-11-0821_27_41.262860/model-00011-0.37613-0.88989-2.30549-0.22000.h5\n",
      "14/14 [==============================] - 330s 24s/step - loss: 0.3761 - categorical_accuracy: 0.8899 - val_loss: 2.3055 - val_categorical_accuracy: 0.2200\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3698 - categorical_accuracy: 0.8959 \n",
      "Epoch 00012: saving model to model_init_2020-11-0821_27_41.262860/model-00012-0.36979-0.89593-2.37613-0.20000.h5\n",
      "14/14 [==============================] - 340s 24s/step - loss: 0.3698 - categorical_accuracy: 0.8959 - val_loss: 2.3761 - val_categorical_accuracy: 0.2000\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3637 - categorical_accuracy: 0.8997 \n",
      "Epoch 00013: saving model to model_init_2020-11-0821_27_41.262860/model-00013-0.36366-0.89970-2.30917-0.19000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "14/14 [==============================] - 330s 24s/step - loss: 0.3637 - categorical_accuracy: 0.8997 - val_loss: 2.3092 - val_categorical_accuracy: 0.1900\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3430 - categorical_accuracy: 0.9125 \n",
      "Epoch 00014: saving model to model_init_2020-11-0821_27_41.262860/model-00014-0.34298-0.91252-2.28387-0.20000.h5\n",
      "14/14 [==============================] - 331s 24s/step - loss: 0.3430 - categorical_accuracy: 0.9125 - val_loss: 2.2839 - val_categorical_accuracy: 0.2000\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3363 - categorical_accuracy: 0.9095 \n",
      "Epoch 00015: saving model to model_init_2020-11-0821_27_41.262860/model-00015-0.33629-0.90950-2.27619-0.19000.h5\n",
      "14/14 [==============================] - 329s 24s/step - loss: 0.3363 - categorical_accuracy: 0.9095 - val_loss: 2.2762 - val_categorical_accuracy: 0.1900\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3287 - categorical_accuracy: 0.9080 \n",
      "Epoch 00016: saving model to model_init_2020-11-0821_27_41.262860/model-00016-0.32865-0.90799-2.24950-0.24000.h5\n",
      "14/14 [==============================] - 356s 25s/step - loss: 0.3287 - categorical_accuracy: 0.9080 - val_loss: 2.2495 - val_categorical_accuracy: 0.2400\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3444 - categorical_accuracy: 0.9080 \n",
      "Epoch 00017: saving model to model_init_2020-11-0821_27_41.262860/model-00017-0.34436-0.90799-2.25174-0.20000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "14/14 [==============================] - 354s 25s/step - loss: 0.3444 - categorical_accuracy: 0.9080 - val_loss: 2.2517 - val_categorical_accuracy: 0.2000\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3408 - categorical_accuracy: 0.8997 \n",
      "Epoch 00018: saving model to model_init_2020-11-0821_27_41.262860/model-00018-0.34076-0.89970-2.25211-0.24000.h5\n",
      "14/14 [==============================] - 339s 24s/step - loss: 0.3408 - categorical_accuracy: 0.8997 - val_loss: 2.2521 - val_categorical_accuracy: 0.2400\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3316 - categorical_accuracy: 0.9163 \n",
      "Epoch 00019: saving model to model_init_2020-11-0821_27_41.262860/model-00019-0.33158-0.91629-2.23399-0.24000.h5\n",
      "14/14 [==============================] - 328s 23s/step - loss: 0.3316 - categorical_accuracy: 0.9163 - val_loss: 2.2340 - val_categorical_accuracy: 0.2400\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3322 - categorical_accuracy: 0.9103 \n",
      "Epoch 00020: saving model to model_init_2020-11-0821_27_41.262860/model-00020-0.33222-0.91026-2.23996-0.23000.h5\n",
      "14/14 [==============================] - 333s 24s/step - loss: 0.3322 - categorical_accuracy: 0.9103 - val_loss: 2.2400 - val_categorical_accuracy: 0.2300\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3394 - categorical_accuracy: 0.9110 \n",
      "Epoch 00021: saving model to model_init_2020-11-0821_27_41.262860/model-00021-0.33942-0.91101-2.21178-0.25000.h5\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "14/14 [==============================] - 335s 24s/step - loss: 0.3394 - categorical_accuracy: 0.9110 - val_loss: 2.2118 - val_categorical_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3281 - categorical_accuracy: 0.9065 \n",
      "Epoch 00022: saving model to model_init_2020-11-0821_27_41.262860/model-00022-0.32810-0.90649-2.32326-0.25000.h5\n",
      "14/14 [==============================] - 334s 24s/step - loss: 0.3281 - categorical_accuracy: 0.9065 - val_loss: 2.3233 - val_categorical_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3337 - categorical_accuracy: 0.9035 \n",
      "Epoch 00023: saving model to model_init_2020-11-0821_27_41.262860/model-00023-0.33368-0.90347-2.19185-0.26000.h5\n",
      "14/14 [==============================] - 329s 24s/step - loss: 0.3337 - categorical_accuracy: 0.9035 - val_loss: 2.1919 - val_categorical_accuracy: 0.2600\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3418 - categorical_accuracy: 0.9012 \n",
      "Epoch 00024: saving model to model_init_2020-11-0821_27_41.262860/model-00024-0.34183-0.90121-2.20758-0.24000.h5\n",
      "14/14 [==============================] - 324s 23s/step - loss: 0.3418 - categorical_accuracy: 0.9012 - val_loss: 2.2076 - val_categorical_accuracy: 0.2400\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3156 - categorical_accuracy: 0.9140 \n",
      "Epoch 00025: saving model to model_init_2020-11-0821_27_41.262860/model-00025-0.31561-0.91403-2.16964-0.25000.h5\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "14/14 [==============================] - 326s 23s/step - loss: 0.3156 - categorical_accuracy: 0.9140 - val_loss: 2.1696 - val_categorical_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3380 - categorical_accuracy: 0.9057 \n",
      "Epoch 00026: saving model to model_init_2020-11-0821_27_41.262860/model-00026-0.33799-0.90573-2.24287-0.17000.h5\n",
      "14/14 [==============================] - 326s 23s/step - loss: 0.3380 - categorical_accuracy: 0.9057 - val_loss: 2.2429 - val_categorical_accuracy: 0.1700\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3258 - categorical_accuracy: 0.9186 \n",
      "Epoch 00027: saving model to model_init_2020-11-0821_27_41.262860/model-00027-0.32576-0.91855-2.14824-0.28000.h5\n",
      "14/14 [==============================] - 323s 23s/step - loss: 0.3258 - categorical_accuracy: 0.9186 - val_loss: 2.1482 - val_categorical_accuracy: 0.2800\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3430 - categorical_accuracy: 0.9050 \n",
      "Epoch 00028: saving model to model_init_2020-11-0821_27_41.262860/model-00028-0.34296-0.90498-2.09952-0.28000.h5\n",
      "14/14 [==============================] - 325s 23s/step - loss: 0.3430 - categorical_accuracy: 0.9050 - val_loss: 2.0995 - val_categorical_accuracy: 0.2800\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3270 - categorical_accuracy: 0.9050 \n",
      "Epoch 00029: saving model to model_init_2020-11-0821_27_41.262860/model-00029-0.32703-0.90498-2.12914-0.29000.h5\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "14/14 [==============================] - 324s 23s/step - loss: 0.3270 - categorical_accuracy: 0.9050 - val_loss: 2.1291 - val_categorical_accuracy: 0.2900\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3378 - categorical_accuracy: 0.9087 \n",
      "Epoch 00030: saving model to model_init_2020-11-0821_27_41.262860/model-00030-0.33778-0.90875-1.95294-0.36000.h5\n",
      "14/14 [==============================] - 323s 23s/step - loss: 0.3378 - categorical_accuracy: 0.9087 - val_loss: 1.9529 - val_categorical_accuracy: 0.3600\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", cnn_lstm1_model.count_params())\n",
    "history_cnn_lstm1_model=rnn_cnn1.train_model(cnn_lstm1_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducing the batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm1=CNN_LSTM()\n",
    "cnn_lstm1.initialize_path(project_folder)\n",
    "cnn_lstm1.initialize_image_properties(image_height=160,image_width=160)\n",
    "cnn_lstm1.initialize_hyperparams(frames_to_sample=18,batch_size=30,num_epochs=30)\n",
    "cnn_lstm1_model=rnn_cnn1.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "cnn_lstm1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Params:\", cnn_lstm1_model.count_params())\n",
    "history_cnn_lstm1_model=rnn_cnn1.train_model(cnn_lstm1_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN_GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_GRU(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
    "                                  input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "        model.add(GRU(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 18, 120, 120, 16)  448       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 18, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 18, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 18, 60, 60, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 18, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 18, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 18, 30, 30, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 18, 30, 30, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 18, 15, 15, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 18, 15, 15, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 18, 15, 15, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 18, 7, 7, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 18, 6272)          0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 128)               2458368   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 2,573,925\n",
      "Trainable params: 2,573,445\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_cnn2=CNN_GRU()\n",
    "rnn_cnn2.initialize_path(project_folder)\n",
    "rnn_cnn2.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn2.initialize_hyperparams(frames_to_sample=18,batch_size=50,num_epochs=30)\n",
    "rnn_cnn2_model=rnn_cnn2.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 2573925\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:From <ipython-input-10-f23cee5fe61d>:125: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.4487 - categorical_accuracy: 0.3771 \n",
      "Epoch 00001: saving model to model_init_2020-11-0909_22_09.410844/model-00001-1.44875-0.37707-1.58272-0.23000.h5\n",
      "14/14 [==============================] - 301s 21s/step - loss: 1.4487 - categorical_accuracy: 0.3771 - val_loss: 1.5827 - val_categorical_accuracy: 0.2300\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9184 - categorical_accuracy: 0.6433 \n",
      "Epoch 00002: saving model to model_init_2020-11-0909_22_09.410844/model-00002-0.91843-0.64329-1.60565-0.32000.h5\n",
      "14/14 [==============================] - 300s 21s/step - loss: 0.9184 - categorical_accuracy: 0.6433 - val_loss: 1.6057 - val_categorical_accuracy: 0.3200\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7073 - categorical_accuracy: 0.7519 \n",
      "Epoch 00003: saving model to model_init_2020-11-0909_22_09.410844/model-00003-0.70730-0.75189-1.69538-0.21000.h5\n",
      "14/14 [==============================] - 299s 21s/step - loss: 0.7073 - categorical_accuracy: 0.7519 - val_loss: 1.6954 - val_categorical_accuracy: 0.2100\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4874 - categorical_accuracy: 0.8507 \n",
      "Epoch 00004: saving model to model_init_2020-11-0909_22_09.410844/model-00004-0.48738-0.85068-1.80821-0.22000.h5\n",
      "14/14 [==============================] - 299s 21s/step - loss: 0.4874 - categorical_accuracy: 0.8507 - val_loss: 1.8082 - val_categorical_accuracy: 0.2200\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3508 - categorical_accuracy: 0.9087 \n",
      "Epoch 00005: saving model to model_init_2020-11-0909_22_09.410844/model-00005-0.35078-0.90875-2.05316-0.21000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n",
      "14/14 [==============================] - 300s 21s/step - loss: 0.3508 - categorical_accuracy: 0.9087 - val_loss: 2.0532 - val_categorical_accuracy: 0.2100\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2528 - categorical_accuracy: 0.9578 \n",
      "Epoch 00006: saving model to model_init_2020-11-0909_22_09.410844/model-00006-0.25285-0.95777-2.18514-0.22000.h5\n",
      "14/14 [==============================] - 300s 21s/step - loss: 0.2528 - categorical_accuracy: 0.9578 - val_loss: 2.1851 - val_categorical_accuracy: 0.2200\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2329 - categorical_accuracy: 0.9600 \n",
      "Epoch 00007: saving model to model_init_2020-11-0909_22_09.410844/model-00007-0.23292-0.96003-2.28999-0.21000.h5\n",
      "14/14 [==============================] - 299s 21s/step - loss: 0.2329 - categorical_accuracy: 0.9600 - val_loss: 2.2900 - val_categorical_accuracy: 0.2100\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1991 - categorical_accuracy: 0.9698 \n",
      "Epoch 00008: saving model to model_init_2020-11-0909_22_09.410844/model-00008-0.19908-0.96983-2.46005-0.18000.h5\n",
      "14/14 [==============================] - 300s 21s/step - loss: 0.1991 - categorical_accuracy: 0.9698 - val_loss: 2.4601 - val_categorical_accuracy: 0.1800\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1880 - categorical_accuracy: 0.9759 \n",
      "Epoch 00009: saving model to model_init_2020-11-0909_22_09.410844/model-00009-0.18796-0.97587-2.44742-0.21000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n",
      "14/14 [==============================] - 301s 21s/step - loss: 0.1880 - categorical_accuracy: 0.9759 - val_loss: 2.4474 - val_categorical_accuracy: 0.2100\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1869 - categorical_accuracy: 0.9751 \n",
      "Epoch 00010: saving model to model_init_2020-11-0909_22_09.410844/model-00010-0.18687-0.97511-2.36525-0.25000.h5\n",
      "14/14 [==============================] - 299s 21s/step - loss: 0.1869 - categorical_accuracy: 0.9751 - val_loss: 2.3652 - val_categorical_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1761 - categorical_accuracy: 0.9827 \n",
      "Epoch 00011: saving model to model_init_2020-11-0909_22_09.410844/model-00011-0.17606-0.98265-2.51747-0.21000.h5\n",
      "14/14 [==============================] - 300s 21s/step - loss: 0.1761 - categorical_accuracy: 0.9827 - val_loss: 2.5175 - val_categorical_accuracy: 0.2100\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1751 - categorical_accuracy: 0.9766 \n",
      "Epoch 00012: saving model to model_init_2020-11-0909_22_09.410844/model-00012-0.17508-0.97662-2.45656-0.22000.h5\n",
      "14/14 [==============================] - 300s 21s/step - loss: 0.1751 - categorical_accuracy: 0.9766 - val_loss: 2.4566 - val_categorical_accuracy: 0.2200\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1640 - categorical_accuracy: 0.9774 \n",
      "Epoch 00013: saving model to model_init_2020-11-0909_22_09.410844/model-00013-0.16401-0.97738-2.54810-0.21000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5999999959603884e-06.\n",
      "14/14 [==============================] - 300s 21s/step - loss: 0.1640 - categorical_accuracy: 0.9774 - val_loss: 2.5481 - val_categorical_accuracy: 0.2100\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1596 - categorical_accuracy: 0.9849 \n",
      "Epoch 00014: saving model to model_init_2020-11-0909_22_09.410844/model-00014-0.15956-0.98492-2.52793-0.21000.h5\n",
      "14/14 [==============================] - 299s 21s/step - loss: 0.1596 - categorical_accuracy: 0.9849 - val_loss: 2.5279 - val_categorical_accuracy: 0.2100\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1716 - categorical_accuracy: 0.9766 \n",
      "Epoch 00015: saving model to model_init_2020-11-0909_22_09.410844/model-00015-0.17159-0.97662-2.56100-0.21000.h5\n",
      "14/14 [==============================] - 306s 22s/step - loss: 0.1716 - categorical_accuracy: 0.9766 - val_loss: 2.5610 - val_categorical_accuracy: 0.2100\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1620 - categorical_accuracy: 0.9804 \n",
      "Epoch 00016: saving model to model_init_2020-11-0909_22_09.410844/model-00016-0.16196-0.98039-2.53128-0.25000.h5\n",
      "14/14 [==============================] - 321s 23s/step - loss: 0.1620 - categorical_accuracy: 0.9804 - val_loss: 2.5313 - val_categorical_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1742 - categorical_accuracy: 0.9744 \n",
      "Epoch 00017: saving model to model_init_2020-11-0909_22_09.410844/model-00017-0.17419-0.97436-2.56608-0.21000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000037395512e-07.\n",
      "14/14 [==============================] - 305s 22s/step - loss: 0.1742 - categorical_accuracy: 0.9744 - val_loss: 2.5661 - val_categorical_accuracy: 0.2100\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1714 - categorical_accuracy: 0.9766 \n",
      "Epoch 00018: saving model to model_init_2020-11-0909_22_09.410844/model-00018-0.17139-0.97662-2.40925-0.25000.h5\n",
      "14/14 [==============================] - 302s 22s/step - loss: 0.1714 - categorical_accuracy: 0.9766 - val_loss: 2.4092 - val_categorical_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1652 - categorical_accuracy: 0.9796 \n",
      "Epoch 00019: saving model to model_init_2020-11-0909_22_09.410844/model-00019-0.16518-0.97964-2.55213-0.24000.h5\n",
      "14/14 [==============================] - 300s 21s/step - loss: 0.1652 - categorical_accuracy: 0.9796 - val_loss: 2.5521 - val_categorical_accuracy: 0.2400\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1611 - categorical_accuracy: 0.9819 \n",
      "Epoch 00020: saving model to model_init_2020-11-0909_22_09.410844/model-00020-0.16110-0.98190-2.51650-0.27000.h5\n",
      "14/14 [==============================] - 309s 22s/step - loss: 0.1611 - categorical_accuracy: 0.9819 - val_loss: 2.5165 - val_categorical_accuracy: 0.2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1680 - categorical_accuracy: 0.9811 \n",
      "Epoch 00021: saving model to model_init_2020-11-0909_22_09.410844/model-00021-0.16801-0.98115-2.52115-0.25000.h5\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.399999961104187e-08.\n",
      "14/14 [==============================] - 315s 22s/step - loss: 0.1680 - categorical_accuracy: 0.9811 - val_loss: 2.5211 - val_categorical_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1587 - categorical_accuracy: 0.9796 \n",
      "Epoch 00022: saving model to model_init_2020-11-0909_22_09.410844/model-00022-0.15867-0.97964-2.18661-0.35000.h5\n",
      "14/14 [==============================] - 306s 22s/step - loss: 0.1587 - categorical_accuracy: 0.9796 - val_loss: 2.1866 - val_categorical_accuracy: 0.3500\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1719 - categorical_accuracy: 0.9781 \n",
      "Epoch 00023: saving model to model_init_2020-11-0909_22_09.410844/model-00023-0.17191-0.97813-2.47771-0.26000.h5\n",
      "14/14 [==============================] - 306s 22s/step - loss: 0.1719 - categorical_accuracy: 0.9781 - val_loss: 2.4777 - val_categorical_accuracy: 0.2600\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1571 - categorical_accuracy: 0.9864 \n",
      "Epoch 00024: saving model to model_init_2020-11-0909_22_09.410844/model-00024-0.15711-0.98643-2.38252-0.26000.h5\n",
      "14/14 [==============================] - 306s 22s/step - loss: 0.1571 - categorical_accuracy: 0.9864 - val_loss: 2.3825 - val_categorical_accuracy: 0.2600\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1567 - categorical_accuracy: 0.9811 \n",
      "Epoch 00025: saving model to model_init_2020-11-0909_22_09.410844/model-00025-0.15670-0.98115-2.41011-0.26000.h5\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.2799999637991278e-08.\n",
      "14/14 [==============================] - 309s 22s/step - loss: 0.1567 - categorical_accuracy: 0.9811 - val_loss: 2.4101 - val_categorical_accuracy: 0.2600\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1613 - categorical_accuracy: 0.9811 \n",
      "Epoch 00026: saving model to model_init_2020-11-0909_22_09.410844/model-00026-0.16134-0.98115-2.40811-0.25000.h5\n",
      "14/14 [==============================] - 306s 22s/step - loss: 0.1613 - categorical_accuracy: 0.9811 - val_loss: 2.4081 - val_categorical_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1692 - categorical_accuracy: 0.9766 \n",
      "Epoch 00027: saving model to model_init_2020-11-0909_22_09.410844/model-00027-0.16922-0.97662-2.31966-0.26000.h5\n",
      "14/14 [==============================] - 305s 22s/step - loss: 0.1692 - categorical_accuracy: 0.9766 - val_loss: 2.3197 - val_categorical_accuracy: 0.2600\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1566 - categorical_accuracy: 0.9834 \n",
      "Epoch 00028: saving model to model_init_2020-11-0909_22_09.410844/model-00028-0.15662-0.98341-2.17447-0.25000.h5\n",
      "14/14 [==============================] - 301s 22s/step - loss: 0.1566 - categorical_accuracy: 0.9834 - val_loss: 2.1745 - val_categorical_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1615 - categorical_accuracy: 0.9857 \n",
      "Epoch 00029: saving model to model_init_2020-11-0909_22_09.410844/model-00029-0.16145-0.98567-2.19699-0.28000.h5\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 2.559999856543982e-09.\n",
      "14/14 [==============================] - 303s 22s/step - loss: 0.1615 - categorical_accuracy: 0.9857 - val_loss: 2.1970 - val_categorical_accuracy: 0.2800\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1614 - categorical_accuracy: 0.9804 \n",
      "Epoch 00030: saving model to model_init_2020-11-0909_22_09.410844/model-00030-0.16139-0.98039-2.16213-0.31000.h5\n",
      "14/14 [==============================] - 301s 21s/step - loss: 0.1614 - categorical_accuracy: 0.9804 - val_loss: 2.1621 - val_categorical_accuracy: 0.3100\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", rnn_cnn2_model.count_params())\n",
    "history_model17=rnn_cnn2.train_model(rnn_cnn2_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lowering the Batch Size and checking if it it improving the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_13 (TimeDis (None, 18, 120, 120, 16)  448       \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 18, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 18, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 18, 60, 60, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 18, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 18, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 18, 30, 30, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 18, 30, 30, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 18, 15, 15, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_22 (TimeDis (None, 18, 15, 15, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 18, 15, 15, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 18, 7, 7, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 18, 6272)          0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               2458368   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 2,573,925\n",
      "Trainable params: 2,573,445\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_cnn2=CNN_GRU()\n",
    "rnn_cnn2.initialize_path(project_folder)\n",
    "rnn_cnn2.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn2.initialize_hyperparams(frames_to_sample=18,batch_size=30,num_epochs=30)\n",
    "rnn_cnn2_model=rnn_cnn2.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 2573925\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.4728 - categorical_accuracy: 0.3612 \n",
      "Epoch 00001: saving model to model_init_2020-11-0912_06_38.151126/model-00001-1.47275-0.36124-1.69419-0.21000.h5\n",
      "23/23 [==============================] - 311s 14s/step - loss: 1.4728 - categorical_accuracy: 0.3612 - val_loss: 1.6942 - val_categorical_accuracy: 0.2100\n",
      "Epoch 2/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.9660 - categorical_accuracy: 0.6275 \n",
      "Epoch 00002: saving model to model_init_2020-11-0912_06_38.151126/model-00002-0.96599-0.62745-2.11128-0.20000.h5\n",
      "23/23 [==============================] - 310s 13s/step - loss: 0.9660 - categorical_accuracy: 0.6275 - val_loss: 2.1113 - val_categorical_accuracy: 0.2000\n",
      "Epoch 3/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.7147 - categorical_accuracy: 0.7572 \n",
      "Epoch 00003: saving model to model_init_2020-11-0912_06_38.151126/model-00003-0.71467-0.75716-2.06322-0.24000.h5\n",
      "23/23 [==============================] - 310s 13s/step - loss: 0.7147 - categorical_accuracy: 0.7572 - val_loss: 2.0632 - val_categorical_accuracy: 0.2400\n",
      "Epoch 4/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5109 - categorical_accuracy: 0.8590 \n",
      "Epoch 00004: saving model to model_init_2020-11-0912_06_38.151126/model-00004-0.51086-0.85897-2.61904-0.17000.h5\n",
      "23/23 [==============================] - 310s 13s/step - loss: 0.5109 - categorical_accuracy: 0.8590 - val_loss: 2.6190 - val_categorical_accuracy: 0.1700\n",
      "Epoch 5/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.3622 - categorical_accuracy: 0.9065 \n",
      "Epoch 00005: saving model to model_init_2020-11-0912_06_38.151126/model-00005-0.36222-0.90649-2.72085-0.21000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n",
      "23/23 [==============================] - 311s 14s/step - loss: 0.3622 - categorical_accuracy: 0.9065 - val_loss: 2.7208 - val_categorical_accuracy: 0.2100\n",
      "Epoch 6/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2748 - categorical_accuracy: 0.9465 \n",
      "Epoch 00006: saving model to model_init_2020-11-0912_06_38.151126/model-00006-0.27482-0.94646-2.82800-0.21000.h5\n",
      "23/23 [==============================] - 310s 13s/step - loss: 0.2748 - categorical_accuracy: 0.9465 - val_loss: 2.8280 - val_categorical_accuracy: 0.2100\n",
      "Epoch 7/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2206 - categorical_accuracy: 0.9646 \n",
      "Epoch 00007: saving model to model_init_2020-11-0912_06_38.151126/model-00007-0.22063-0.96456-2.90591-0.23000.h5\n",
      "23/23 [==============================] - 310s 13s/step - loss: 0.2206 - categorical_accuracy: 0.9646 - val_loss: 2.9059 - val_categorical_accuracy: 0.2300\n",
      "Epoch 8/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1875 - categorical_accuracy: 0.9774 \n",
      "Epoch 00008: saving model to model_init_2020-11-0912_06_38.151126/model-00008-0.18750-0.97738-2.91801-0.24000.h5\n",
      "23/23 [==============================] - 313s 14s/step - loss: 0.1875 - categorical_accuracy: 0.9774 - val_loss: 2.9180 - val_categorical_accuracy: 0.2400\n",
      "Epoch 9/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1795 - categorical_accuracy: 0.9759 \n",
      "Epoch 00009: saving model to model_init_2020-11-0912_06_38.151126/model-00009-0.17947-0.97587-3.07415-0.21000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n",
      "23/23 [==============================] - 311s 14s/step - loss: 0.1795 - categorical_accuracy: 0.9759 - val_loss: 3.0741 - val_categorical_accuracy: 0.2100\n",
      "Epoch 10/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1545 - categorical_accuracy: 0.9834 \n",
      "Epoch 00010: saving model to model_init_2020-11-0912_06_38.151126/model-00010-0.15453-0.98341-2.98363-0.24000.h5\n",
      "23/23 [==============================] - 325s 14s/step - loss: 0.1545 - categorical_accuracy: 0.9834 - val_loss: 2.9836 - val_categorical_accuracy: 0.2400\n",
      "Epoch 11/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1643 - categorical_accuracy: 0.9819 \n",
      "Epoch 00011: saving model to model_init_2020-11-0912_06_38.151126/model-00011-0.16432-0.98190-3.16943-0.18000.h5\n",
      "23/23 [==============================] - 311s 14s/step - loss: 0.1643 - categorical_accuracy: 0.9819 - val_loss: 3.1694 - val_categorical_accuracy: 0.1800\n",
      "Epoch 12/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1534 - categorical_accuracy: 0.9804 \n",
      "Epoch 00012: saving model to model_init_2020-11-0912_06_38.151126/model-00012-0.15342-0.98039-2.96026-0.24000.h5\n",
      "23/23 [==============================] - 308s 13s/step - loss: 0.1534 - categorical_accuracy: 0.9804 - val_loss: 2.9603 - val_categorical_accuracy: 0.2400\n",
      "Epoch 13/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1456 - categorical_accuracy: 0.9849 \n",
      "Epoch 00013: saving model to model_init_2020-11-0912_06_38.151126/model-00013-0.14561-0.98492-3.04715-0.21000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5999999959603884e-06.\n",
      "23/23 [==============================] - 309s 13s/step - loss: 0.1456 - categorical_accuracy: 0.9849 - val_loss: 3.0472 - val_categorical_accuracy: 0.2100\n",
      "Epoch 14/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1480 - categorical_accuracy: 0.9849 \n",
      "Epoch 00014: saving model to model_init_2020-11-0912_06_38.151126/model-00014-0.14798-0.98492-2.93928-0.23000.h5\n",
      "23/23 [==============================] - 308s 13s/step - loss: 0.1480 - categorical_accuracy: 0.9849 - val_loss: 2.9393 - val_categorical_accuracy: 0.2300\n",
      "Epoch 15/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1522 - categorical_accuracy: 0.9827 \n",
      "Epoch 00015: saving model to model_init_2020-11-0912_06_38.151126/model-00015-0.15216-0.98265-2.70317-0.24000.h5\n",
      "23/23 [==============================] - 309s 13s/step - loss: 0.1522 - categorical_accuracy: 0.9827 - val_loss: 2.7032 - val_categorical_accuracy: 0.2400\n",
      "Epoch 16/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1525 - categorical_accuracy: 0.9827 \n",
      "Epoch 00016: saving model to model_init_2020-11-0912_06_38.151126/model-00016-0.15251-0.98265-2.76059-0.24000.h5\n",
      "23/23 [==============================] - 308s 13s/step - loss: 0.1525 - categorical_accuracy: 0.9827 - val_loss: 2.7606 - val_categorical_accuracy: 0.2400\n",
      "Epoch 17/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1450 - categorical_accuracy: 0.9872 \n",
      "Epoch 00017: saving model to model_init_2020-11-0912_06_38.151126/model-00017-0.14497-0.98718-2.46488-0.29000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.200000037395512e-07.\n",
      "23/23 [==============================] - 309s 13s/step - loss: 0.1450 - categorical_accuracy: 0.9872 - val_loss: 2.4649 - val_categorical_accuracy: 0.2900\n",
      "Epoch 18/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1541 - categorical_accuracy: 0.9811 \n",
      "Epoch 00018: saving model to model_init_2020-11-0912_06_38.151126/model-00018-0.15414-0.98115-2.29251-0.33000.h5\n",
      "23/23 [==============================] - 308s 13s/step - loss: 0.1541 - categorical_accuracy: 0.9811 - val_loss: 2.2925 - val_categorical_accuracy: 0.3300\n",
      "Epoch 19/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1439 - categorical_accuracy: 0.9819 \n",
      "Epoch 00019: saving model to model_init_2020-11-0912_06_38.151126/model-00019-0.14391-0.98190-2.04064-0.33000.h5\n",
      "23/23 [==============================] - 309s 13s/step - loss: 0.1439 - categorical_accuracy: 0.9819 - val_loss: 2.0406 - val_categorical_accuracy: 0.3300\n",
      "Epoch 20/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1380 - categorical_accuracy: 0.9857 \n",
      "Epoch 00020: saving model to model_init_2020-11-0912_06_38.151126/model-00020-0.13800-0.98567-1.85053-0.41000.h5\n",
      "23/23 [==============================] - 309s 13s/step - loss: 0.1380 - categorical_accuracy: 0.9857 - val_loss: 1.8505 - val_categorical_accuracy: 0.4100\n",
      "Epoch 21/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1488 - categorical_accuracy: 0.9872 \n",
      "Epoch 00021: saving model to model_init_2020-11-0912_06_38.151126/model-00021-0.14878-0.98718-1.63686-0.44000.h5\n",
      "23/23 [==============================] - 309s 13s/step - loss: 0.1488 - categorical_accuracy: 0.9872 - val_loss: 1.6369 - val_categorical_accuracy: 0.4400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1394 - categorical_accuracy: 0.9857 \n",
      "Epoch 00022: saving model to model_init_2020-11-0912_06_38.151126/model-00022-0.13944-0.98567-1.53549-0.43000.h5\n",
      "23/23 [==============================] - 308s 13s/step - loss: 0.1394 - categorical_accuracy: 0.9857 - val_loss: 1.5355 - val_categorical_accuracy: 0.4300\n",
      "Epoch 23/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1454 - categorical_accuracy: 0.9796 \n",
      "Epoch 00023: saving model to model_init_2020-11-0912_06_38.151126/model-00023-0.14539-0.97964-1.25033-0.55000.h5\n",
      "23/23 [==============================] - 308s 13s/step - loss: 0.1454 - categorical_accuracy: 0.9796 - val_loss: 1.2503 - val_categorical_accuracy: 0.5500\n",
      "Epoch 24/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1495 - categorical_accuracy: 0.9827 \n",
      "Epoch 00024: saving model to model_init_2020-11-0912_06_38.151126/model-00024-0.14945-0.98265-1.22451-0.55000.h5\n",
      "23/23 [==============================] - 313s 14s/step - loss: 0.1495 - categorical_accuracy: 0.9827 - val_loss: 1.2245 - val_categorical_accuracy: 0.5500\n",
      "Epoch 25/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1376 - categorical_accuracy: 0.9894 \n",
      "Epoch 00025: saving model to model_init_2020-11-0912_06_38.151126/model-00025-0.13762-0.98944-1.09711-0.60000.h5\n",
      "23/23 [==============================] - 313s 14s/step - loss: 0.1376 - categorical_accuracy: 0.9894 - val_loss: 1.0971 - val_categorical_accuracy: 0.6000\n",
      "Epoch 26/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1437 - categorical_accuracy: 0.9902 \n",
      "Epoch 00026: saving model to model_init_2020-11-0912_06_38.151126/model-00026-0.14368-0.99020-1.08263-0.60000.h5\n",
      "23/23 [==============================] - 307s 13s/step - loss: 0.1437 - categorical_accuracy: 0.9902 - val_loss: 1.0826 - val_categorical_accuracy: 0.6000\n",
      "Epoch 27/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1447 - categorical_accuracy: 0.9842 \n",
      "Epoch 00027: saving model to model_init_2020-11-0912_06_38.151126/model-00027-0.14468-0.98416-0.86740-0.64000.h5\n",
      "23/23 [==============================] - 312s 14s/step - loss: 0.1447 - categorical_accuracy: 0.9842 - val_loss: 0.8674 - val_categorical_accuracy: 0.6400\n",
      "Epoch 28/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1443 - categorical_accuracy: 0.9849 \n",
      "Epoch 00028: saving model to model_init_2020-11-0912_06_38.151126/model-00028-0.14430-0.98492-0.90326-0.61000.h5\n",
      "23/23 [==============================] - 322s 14s/step - loss: 0.1443 - categorical_accuracy: 0.9849 - val_loss: 0.9033 - val_categorical_accuracy: 0.6100\n",
      "Epoch 29/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1385 - categorical_accuracy: 0.9864 \n",
      "Epoch 00029: saving model to model_init_2020-11-0912_06_38.151126/model-00029-0.13848-0.98643-0.85029-0.68000.h5\n",
      "23/23 [==============================] - 312s 14s/step - loss: 0.1385 - categorical_accuracy: 0.9864 - val_loss: 0.8503 - val_categorical_accuracy: 0.6800\n",
      "Epoch 30/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1419 - categorical_accuracy: 0.9834 \n",
      "Epoch 00030: saving model to model_init_2020-11-0912_06_38.151126/model-00030-0.14193-0.98341-0.79750-0.69000.h5\n",
      "23/23 [==============================] - 309s 13s/step - loss: 0.1419 - categorical_accuracy: 0.9834 - val_loss: 0.7975 - val_categorical_accuracy: 0.6900\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", rnn_cnn2_model.count_params())\n",
    "history_model17=rnn_cnn2.train_model(rnn_cnn2_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducing the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_26 (TimeDis (None, 18, 120, 120, 16)  448       \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 18, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 18, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_29 (TimeDis (None, 18, 60, 60, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_30 (TimeDis (None, 18, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 18, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_32 (TimeDis (None, 18, 30, 30, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_33 (TimeDis (None, 18, 30, 30, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_34 (TimeDis (None, 18, 15, 15, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_35 (TimeDis (None, 18, 15, 15, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_36 (TimeDis (None, 18, 15, 15, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_37 (TimeDis (None, 18, 7, 7, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_38 (TimeDis (None, 18, 6272)          0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 128)               2458368   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 2,573,925\n",
      "Trainable params: 2,573,445\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_cnn2=CNN_GRU()\n",
    "rnn_cnn2.initialize_path(project_folder)\n",
    "rnn_cnn2.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn2.initialize_hyperparams(frames_to_sample=18,batch_size=20,num_epochs=30)\n",
    "rnn_cnn2_model=rnn_cnn2.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 2573925\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.4653 - categorical_accuracy: 0.3891\n",
      "Epoch 00001: saving model to model_init_2020-11-0916_51_18.184820/model-00001-1.46535-0.38914-1.72832-0.33000.h5\n",
      "34/34 [==============================] - 317s 9s/step - loss: 1.4653 - categorical_accuracy: 0.3891 - val_loss: 1.7283 - val_categorical_accuracy: 0.3300\n",
      "Epoch 2/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.8955 - categorical_accuracy: 0.6855\n",
      "Epoch 00002: saving model to model_init_2020-11-0916_51_18.184820/model-00002-0.89548-0.68552-2.25163-0.21000.h5\n",
      "34/34 [==============================] - 315s 9s/step - loss: 0.8955 - categorical_accuracy: 0.6855 - val_loss: 2.2516 - val_categorical_accuracy: 0.2100\n",
      "Epoch 3/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6173 - categorical_accuracy: 0.7896\n",
      "Epoch 00003: saving model to model_init_2020-11-0916_51_18.184820/model-00003-0.61731-0.78959-2.76125-0.21000.h5\n",
      "34/34 [==============================] - 314s 9s/step - loss: 0.6173 - categorical_accuracy: 0.7896 - val_loss: 2.7613 - val_categorical_accuracy: 0.2100\n",
      "Epoch 4/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4170 - categorical_accuracy: 0.8967\n",
      "Epoch 00004: saving model to model_init_2020-11-0916_51_18.184820/model-00004-0.41703-0.89668-3.22606-0.18000.h5\n",
      "34/34 [==============================] - 320s 9s/step - loss: 0.4170 - categorical_accuracy: 0.8967 - val_loss: 3.2261 - val_categorical_accuracy: 0.1800\n",
      "Epoch 5/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2638 - categorical_accuracy: 0.9389\n",
      "Epoch 00005: saving model to model_init_2020-11-0916_51_18.184820/model-00005-0.26383-0.93891-3.65497-0.24000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n",
      "34/34 [==============================] - 315s 9s/step - loss: 0.2638 - categorical_accuracy: 0.9389 - val_loss: 3.6550 - val_categorical_accuracy: 0.2400\n",
      "Epoch 6/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1589 - categorical_accuracy: 0.9804\n",
      "Epoch 00006: saving model to model_init_2020-11-0916_51_18.184820/model-00006-0.15891-0.98039-3.95513-0.21000.h5\n",
      "34/34 [==============================] - 313s 9s/step - loss: 0.1589 - categorical_accuracy: 0.9804 - val_loss: 3.9551 - val_categorical_accuracy: 0.2100\n",
      "Epoch 7/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1338 - categorical_accuracy: 0.9925\n",
      "Epoch 00007: saving model to model_init_2020-11-0916_51_18.184820/model-00007-0.13381-0.99246-4.03749-0.20000.h5\n",
      "34/34 [==============================] - 314s 9s/step - loss: 0.1338 - categorical_accuracy: 0.9925 - val_loss: 4.0375 - val_categorical_accuracy: 0.2000\n",
      "Epoch 8/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1187 - categorical_accuracy: 0.9902\n",
      "Epoch 00008: saving model to model_init_2020-11-0916_51_18.184820/model-00008-0.11870-0.99020-3.94156-0.19000.h5\n",
      "34/34 [==============================] - 315s 9s/step - loss: 0.1187 - categorical_accuracy: 0.9902 - val_loss: 3.9416 - val_categorical_accuracy: 0.1900\n",
      "Epoch 9/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1002 - categorical_accuracy: 0.9970\n",
      "Epoch 00009: saving model to model_init_2020-11-0916_51_18.184820/model-00009-0.10024-0.99698-4.00264-0.17000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n",
      "34/34 [==============================] - 314s 9s/step - loss: 0.1002 - categorical_accuracy: 0.9970 - val_loss: 4.0026 - val_categorical_accuracy: 0.1700\n",
      "Epoch 10/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1046 - categorical_accuracy: 0.9887\n",
      "Epoch 00010: saving model to model_init_2020-11-0916_51_18.184820/model-00010-0.10461-0.98869-3.38399-0.25000.h5\n",
      "34/34 [==============================] - 313s 9s/step - loss: 0.1046 - categorical_accuracy: 0.9887 - val_loss: 3.3840 - val_categorical_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0949 - categorical_accuracy: 0.9947\n",
      "Epoch 00011: saving model to model_init_2020-11-0916_51_18.184820/model-00011-0.09489-0.99472-3.18183-0.25000.h5\n",
      "34/34 [==============================] - 313s 9s/step - loss: 0.0949 - categorical_accuracy: 0.9947 - val_loss: 3.1818 - val_categorical_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0981 - categorical_accuracy: 0.9925\n",
      "Epoch 00012: saving model to model_init_2020-11-0916_51_18.184820/model-00012-0.09811-0.99246-2.93973-0.24000.h5\n",
      "34/34 [==============================] - 330s 10s/step - loss: 0.0981 - categorical_accuracy: 0.9925 - val_loss: 2.9397 - val_categorical_accuracy: 0.2400\n",
      "Epoch 13/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0904 - categorical_accuracy: 0.9947\n",
      "Epoch 00013: saving model to model_init_2020-11-0916_51_18.184820/model-00013-0.09037-0.99472-2.31622-0.36000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5999999959603884e-06.\n",
      "34/34 [==============================] - 316s 9s/step - loss: 0.0904 - categorical_accuracy: 0.9947 - val_loss: 2.3162 - val_categorical_accuracy: 0.3600\n",
      "Epoch 14/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0926 - categorical_accuracy: 0.9932\n",
      "Epoch 00014: saving model to model_init_2020-11-0916_51_18.184820/model-00014-0.09262-0.99321-2.02595-0.39000.h5\n",
      "34/34 [==============================] - 316s 9s/step - loss: 0.0926 - categorical_accuracy: 0.9932 - val_loss: 2.0259 - val_categorical_accuracy: 0.3900\n",
      "Epoch 15/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0864 - categorical_accuracy: 0.9962\n",
      "Epoch 00015: saving model to model_init_2020-11-0916_51_18.184820/model-00015-0.08640-0.99623-1.48078-0.47000.h5\n",
      "34/34 [==============================] - 317s 9s/step - loss: 0.0864 - categorical_accuracy: 0.9962 - val_loss: 1.4808 - val_categorical_accuracy: 0.4700\n",
      "Epoch 16/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0822 - categorical_accuracy: 0.9962\n",
      "Epoch 00016: saving model to model_init_2020-11-0916_51_18.184820/model-00016-0.08215-0.99623-1.31780-0.54000.h5\n",
      "34/34 [==============================] - 322s 9s/step - loss: 0.0822 - categorical_accuracy: 0.9962 - val_loss: 1.3178 - val_categorical_accuracy: 0.5400\n",
      "Epoch 17/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0941 - categorical_accuracy: 0.9932\n",
      "Epoch 00017: saving model to model_init_2020-11-0916_51_18.184820/model-00017-0.09408-0.99321-1.25641-0.59000.h5\n",
      "34/34 [==============================] - 317s 9s/step - loss: 0.0941 - categorical_accuracy: 0.9932 - val_loss: 1.2564 - val_categorical_accuracy: 0.5900\n",
      "Epoch 18/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0859 - categorical_accuracy: 0.9962\n",
      "Epoch 00018: saving model to model_init_2020-11-0916_51_18.184820/model-00018-0.08587-0.99623-0.87137-0.64000.h5\n",
      "34/34 [==============================] - 318s 9s/step - loss: 0.0859 - categorical_accuracy: 0.9962 - val_loss: 0.8714 - val_categorical_accuracy: 0.6400\n",
      "Epoch 19/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0876 - categorical_accuracy: 0.9947\n",
      "Epoch 00019: saving model to model_init_2020-11-0916_51_18.184820/model-00019-0.08764-0.99472-0.83357-0.71000.h5\n",
      "34/34 [==============================] - 317s 9s/step - loss: 0.0876 - categorical_accuracy: 0.9947 - val_loss: 0.8336 - val_categorical_accuracy: 0.7100\n",
      "Epoch 20/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0875 - categorical_accuracy: 0.9962\n",
      "Epoch 00020: saving model to model_init_2020-11-0916_51_18.184820/model-00020-0.08753-0.99623-0.80323-0.74000.h5\n",
      "34/34 [==============================] - 319s 9s/step - loss: 0.0875 - categorical_accuracy: 0.9962 - val_loss: 0.8032 - val_categorical_accuracy: 0.7400\n",
      "Epoch 21/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0876 - categorical_accuracy: 0.9970\n",
      "Epoch 00021: saving model to model_init_2020-11-0916_51_18.184820/model-00021-0.08757-0.99698-0.73360-0.75000.h5\n",
      "34/34 [==============================] - 318s 9s/step - loss: 0.0876 - categorical_accuracy: 0.9970 - val_loss: 0.7336 - val_categorical_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0805 - categorical_accuracy: 0.9992\n",
      "Epoch 00022: saving model to model_init_2020-11-0916_51_18.184820/model-00022-0.08054-0.99925-0.73457-0.73000.h5\n",
      "34/34 [==============================] - 316s 9s/step - loss: 0.0805 - categorical_accuracy: 0.9992 - val_loss: 0.7346 - val_categorical_accuracy: 0.7300\n",
      "Epoch 23/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0823 - categorical_accuracy: 0.9985\n",
      "Epoch 00023: saving model to model_init_2020-11-0916_51_18.184820/model-00023-0.08230-0.99849-0.57033-0.81000.h5\n",
      "34/34 [==============================] - 318s 9s/step - loss: 0.0823 - categorical_accuracy: 0.9985 - val_loss: 0.5703 - val_categorical_accuracy: 0.8100\n",
      "Epoch 24/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0884 - categorical_accuracy: 0.9932\n",
      "Epoch 00024: saving model to model_init_2020-11-0916_51_18.184820/model-00024-0.08843-0.99321-0.79388-0.72000.h5\n",
      "34/34 [==============================] - 318s 9s/step - loss: 0.0884 - categorical_accuracy: 0.9932 - val_loss: 0.7939 - val_categorical_accuracy: 0.7200\n",
      "Epoch 25/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0878 - categorical_accuracy: 0.9955\n",
      "Epoch 00025: saving model to model_init_2020-11-0916_51_18.184820/model-00025-0.08777-0.99548-0.64566-0.80000.h5\n",
      "34/34 [==============================] - 316s 9s/step - loss: 0.0878 - categorical_accuracy: 0.9955 - val_loss: 0.6457 - val_categorical_accuracy: 0.8000\n",
      "Epoch 26/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0885 - categorical_accuracy: 0.9925\n",
      "Epoch 00026: saving model to model_init_2020-11-0916_51_18.184820/model-00026-0.08851-0.99246-0.66553-0.77000.h5\n",
      "34/34 [==============================] - 317s 9s/step - loss: 0.0885 - categorical_accuracy: 0.9925 - val_loss: 0.6655 - val_categorical_accuracy: 0.7700\n",
      "Epoch 27/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0886 - categorical_accuracy: 0.9910\n",
      "Epoch 00027: saving model to model_init_2020-11-0916_51_18.184820/model-00027-0.08861-0.99095-0.75665-0.77000.h5\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.200000037395512e-07.\n",
      "34/34 [==============================] - 317s 9s/step - loss: 0.0886 - categorical_accuracy: 0.9910 - val_loss: 0.7567 - val_categorical_accuracy: 0.7700\n",
      "Epoch 28/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0839 - categorical_accuracy: 0.9932\n",
      "Epoch 00028: saving model to model_init_2020-11-0916_51_18.184820/model-00028-0.08391-0.99321-0.60301-0.77000.h5\n",
      "34/34 [==============================] - 317s 9s/step - loss: 0.0839 - categorical_accuracy: 0.9932 - val_loss: 0.6030 - val_categorical_accuracy: 0.7700\n",
      "Epoch 29/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0828 - categorical_accuracy: 0.9962\n",
      "Epoch 00029: saving model to model_init_2020-11-0916_51_18.184820/model-00029-0.08284-0.99623-0.57049-0.85000.h5\n",
      "34/34 [==============================] - 317s 9s/step - loss: 0.0828 - categorical_accuracy: 0.9962 - val_loss: 0.5705 - val_categorical_accuracy: 0.8500\n",
      "Epoch 30/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0810 - categorical_accuracy: 0.9977\n",
      "Epoch 00030: saving model to model_init_2020-11-0916_51_18.184820/model-00030-0.08103-0.99774-0.73592-0.74000.h5\n",
      "34/34 [==============================] - 317s 9s/step - loss: 0.0810 - categorical_accuracy: 0.9977 - val_loss: 0.7359 - val_categorical_accuracy: 0.7400\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", rnn_cnn2_model.count_params())\n",
    "history_model17=rnn_cnn2.train_model(rnn_cnn2_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import mobilenet\n",
    "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "class CNN_RNN_LSTM_TL(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(mobilenet_transfer,input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        \n",
    "        \n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        \n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(LSTM(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        \n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_47 (TimeDis (None, 18, 3, 3, 1024)    3228864   \n",
      "_________________________________________________________________\n",
      "time_distributed_48 (TimeDis (None, 18, 3, 3, 1024)    4096      \n",
      "_________________________________________________________________\n",
      "time_distributed_49 (TimeDis (None, 18, 1, 1, 1024)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_50 (TimeDis (None, 18, 1024)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               590336    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,840,453\n",
      "Trainable params: 609,541\n",
      "Non-trainable params: 3,230,912\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_cnn_tl=CNN_RNN_LSTM_TL()\n",
    "rnn_cnn_tl.initialize_path(project_folder)\n",
    "rnn_cnn_tl.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn_tl.initialize_hyperparams(frames_to_sample=18,batch_size=20,num_epochs=25)\n",
    "rnn_cnn_tl_model=rnn_cnn_tl.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn_tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3840453\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.4070 - categorical_accuracy: 0.3952\n",
      "Epoch 00001: saving model to model_init_2020-11-0919_52_33.773476/model-00001-1.40695-0.39517-1.32648-0.44000.h5\n",
      "34/34 [==============================] - 190s 6s/step - loss: 1.4070 - categorical_accuracy: 0.3952 - val_loss: 1.3265 - val_categorical_accuracy: 0.4400\n",
      "Epoch 2/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7331 - categorical_accuracy: 0.7466\n",
      "Epoch 00002: saving model to model_init_2020-11-0919_52_33.773476/model-00002-0.73314-0.74661-1.00794-0.64000.h5\n",
      "34/34 [==============================] - 197s 6s/step - loss: 0.7331 - categorical_accuracy: 0.7466 - val_loss: 1.0079 - val_categorical_accuracy: 0.6400\n",
      "Epoch 3/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3533 - categorical_accuracy: 0.8876\n",
      "Epoch 00003: saving model to model_init_2020-11-0919_52_33.773476/model-00003-0.35331-0.88763-0.83833-0.68000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.3533 - categorical_accuracy: 0.8876 - val_loss: 0.8383 - val_categorical_accuracy: 0.6800\n",
      "Epoch 4/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1619 - categorical_accuracy: 0.9668\n",
      "Epoch 00004: saving model to model_init_2020-11-0919_52_33.773476/model-00004-0.16185-0.96682-0.73235-0.69000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.1619 - categorical_accuracy: 0.9668 - val_loss: 0.7324 - val_categorical_accuracy: 0.6900\n",
      "Epoch 5/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0805 - categorical_accuracy: 0.9864\n",
      "Epoch 00005: saving model to model_init_2020-11-0919_52_33.773476/model-00005-0.08048-0.98643-0.93105-0.64000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0805 - categorical_accuracy: 0.9864 - val_loss: 0.9311 - val_categorical_accuracy: 0.6400\n",
      "Epoch 6/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0404 - categorical_accuracy: 0.9925\n",
      "Epoch 00006: saving model to model_init_2020-11-0919_52_33.773476/model-00006-0.04044-0.99246-1.04065-0.61000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0404 - categorical_accuracy: 0.9925 - val_loss: 1.0407 - val_categorical_accuracy: 0.6100\n",
      "Epoch 7/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0243 - categorical_accuracy: 0.9970\n",
      "Epoch 00007: saving model to model_init_2020-11-0919_52_33.773476/model-00007-0.02426-0.99698-1.00547-0.66000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0243 - categorical_accuracy: 0.9970 - val_loss: 1.0055 - val_categorical_accuracy: 0.6600\n",
      "Epoch 8/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0144 - categorical_accuracy: 0.9985\n",
      "Epoch 00008: saving model to model_init_2020-11-0919_52_33.773476/model-00008-0.01440-0.99849-1.30423-0.61000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0144 - categorical_accuracy: 0.9985 - val_loss: 1.3042 - val_categorical_accuracy: 0.6100\n",
      "Epoch 9/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0094 - categorical_accuracy: 0.9992\n",
      "Epoch 00009: saving model to model_init_2020-11-0919_52_33.773476/model-00009-0.00937-0.99925-1.10602-0.68000.h5\n",
      "34/34 [==============================] - 194s 6s/step - loss: 0.0094 - categorical_accuracy: 0.9992 - val_loss: 1.1060 - val_categorical_accuracy: 0.6800\n",
      "Epoch 10/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0094 - categorical_accuracy: 1.0000\n",
      "Epoch 00010: saving model to model_init_2020-11-0919_52_33.773476/model-00010-0.00939-1.00000-1.14223-0.64000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0094 - categorical_accuracy: 1.0000 - val_loss: 1.1422 - val_categorical_accuracy: 0.6400\n",
      "Epoch 11/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0072 - categorical_accuracy: 1.0000\n",
      "Epoch 00011: saving model to model_init_2020-11-0919_52_33.773476/model-00011-0.00724-1.00000-1.11027-0.69000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0072 - categorical_accuracy: 1.0000 - val_loss: 1.1103 - val_categorical_accuracy: 0.6900\n",
      "Epoch 12/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0079 - categorical_accuracy: 0.9992\n",
      "Epoch 00012: saving model to model_init_2020-11-0919_52_33.773476/model-00012-0.00791-0.99925-0.92490-0.71000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "34/34 [==============================] - 194s 6s/step - loss: 0.0079 - categorical_accuracy: 0.9992 - val_loss: 0.9249 - val_categorical_accuracy: 0.7100\n",
      "Epoch 13/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0078 - categorical_accuracy: 1.0000\n",
      "Epoch 00013: saving model to model_init_2020-11-0919_52_33.773476/model-00013-0.00776-1.00000-1.12837-0.64000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0078 - categorical_accuracy: 1.0000 - val_loss: 1.1284 - val_categorical_accuracy: 0.6400\n",
      "Epoch 14/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0078 - categorical_accuracy: 1.0000\n",
      "Epoch 00014: saving model to model_init_2020-11-0919_52_33.773476/model-00014-0.00776-1.00000-1.08810-0.64000.h5\n",
      "34/34 [==============================] - 194s 6s/step - loss: 0.0078 - categorical_accuracy: 1.0000 - val_loss: 1.0881 - val_categorical_accuracy: 0.6400\n",
      "Epoch 15/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0058 - categorical_accuracy: 0.9992\n",
      "Epoch 00015: saving model to model_init_2020-11-0919_52_33.773476/model-00015-0.00578-0.99925-1.05392-0.68000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0058 - categorical_accuracy: 0.9992 - val_loss: 1.0539 - val_categorical_accuracy: 0.6800\n",
      "Epoch 16/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0064 - categorical_accuracy: 0.9992\n",
      "Epoch 00016: saving model to model_init_2020-11-0919_52_33.773476/model-00016-0.00645-0.99925-1.12141-0.67000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "34/34 [==============================] - 194s 6s/step - loss: 0.0064 - categorical_accuracy: 0.9992 - val_loss: 1.1214 - val_categorical_accuracy: 0.6700\n",
      "Epoch 17/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0054 - categorical_accuracy: 1.0000\n",
      "Epoch 00017: saving model to model_init_2020-11-0919_52_33.773476/model-00017-0.00544-1.00000-1.09738-0.67000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0054 - categorical_accuracy: 1.0000 - val_loss: 1.0974 - val_categorical_accuracy: 0.6700\n",
      "Epoch 18/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0048 - categorical_accuracy: 1.0000\n",
      "Epoch 00018: saving model to model_init_2020-11-0919_52_33.773476/model-00018-0.00475-1.00000-1.05642-0.66000.h5\n",
      "34/34 [==============================] - 194s 6s/step - loss: 0.0048 - categorical_accuracy: 1.0000 - val_loss: 1.0564 - val_categorical_accuracy: 0.6600\n",
      "Epoch 19/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0050 - categorical_accuracy: 1.0000\n",
      "Epoch 00019: saving model to model_init_2020-11-0919_52_33.773476/model-00019-0.00501-1.00000-1.35863-0.66000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0050 - categorical_accuracy: 1.0000 - val_loss: 1.3586 - val_categorical_accuracy: 0.6600\n",
      "Epoch 20/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0056 - categorical_accuracy: 1.0000\n",
      "Epoch 00020: saving model to model_init_2020-11-0919_52_33.773476/model-00020-0.00564-1.00000-1.10525-0.65000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0056 - categorical_accuracy: 1.0000 - val_loss: 1.1052 - val_categorical_accuracy: 0.6500\n",
      "Epoch 21/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0062 - categorical_accuracy: 0.9992\n",
      "Epoch 00021: saving model to model_init_2020-11-0919_52_33.773476/model-00021-0.00618-0.99925-1.12431-0.67000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0062 - categorical_accuracy: 0.9992 - val_loss: 1.1243 - val_categorical_accuracy: 0.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0059 - categorical_accuracy: 1.0000\n",
      "Epoch 00022: saving model to model_init_2020-11-0919_52_33.773476/model-00022-0.00594-1.00000-1.15571-0.69000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0059 - categorical_accuracy: 1.0000 - val_loss: 1.1557 - val_categorical_accuracy: 0.6900\n",
      "Epoch 23/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0059 - categorical_accuracy: 1.0000\n",
      "Epoch 00023: saving model to model_init_2020-11-0919_52_33.773476/model-00023-0.00585-1.00000-1.08524-0.64000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0059 - categorical_accuracy: 1.0000 - val_loss: 1.0852 - val_categorical_accuracy: 0.6400\n",
      "Epoch 24/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0056 - categorical_accuracy: 1.0000\n",
      "Epoch 00024: saving model to model_init_2020-11-0919_52_33.773476/model-00024-0.00563-1.00000-1.30749-0.64000.h5\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "34/34 [==============================] - 197s 6s/step - loss: 0.0056 - categorical_accuracy: 1.0000 - val_loss: 1.3075 - val_categorical_accuracy: 0.6400\n",
      "Epoch 25/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0053 - categorical_accuracy: 1.0000\n",
      "Epoch 00025: saving model to model_init_2020-11-0919_52_33.773476/model-00025-0.00532-1.00000-1.08840-0.67000.h5\n",
      "34/34 [==============================] - 194s 6s/step - loss: 0.0053 - categorical_accuracy: 1.0000 - val_loss: 1.0884 - val_categorical_accuracy: 0.6700\n",
      "Epoch 26/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0052 - categorical_accuracy: 1.0000\n",
      "Epoch 00026: saving model to model_init_2020-11-0919_52_33.773476/model-00026-0.00520-1.00000-1.12186-0.67000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0052 - categorical_accuracy: 1.0000 - val_loss: 1.1219 - val_categorical_accuracy: 0.6700\n",
      "Epoch 27/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0048 - categorical_accuracy: 1.0000\n",
      "Epoch 00027: saving model to model_init_2020-11-0919_52_33.773476/model-00027-0.00475-1.00000-1.31244-0.65000.h5\n",
      "34/34 [==============================] - 194s 6s/step - loss: 0.0048 - categorical_accuracy: 1.0000 - val_loss: 1.3124 - val_categorical_accuracy: 0.6500\n",
      "Epoch 28/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0047 - categorical_accuracy: 1.0000\n",
      "Epoch 00028: saving model to model_init_2020-11-0919_52_33.773476/model-00028-0.00475-1.00000-1.15471-0.67000.h5\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0047 - categorical_accuracy: 1.0000 - val_loss: 1.1547 - val_categorical_accuracy: 0.6700\n",
      "Epoch 29/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0135 - categorical_accuracy: 0.9985\n",
      "Epoch 00029: saving model to model_init_2020-11-0919_52_33.773476/model-00029-0.01346-0.99849-1.08200-0.64000.h5\n",
      "34/34 [==============================] - 195s 6s/step - loss: 0.0135 - categorical_accuracy: 0.9985 - val_loss: 1.0820 - val_categorical_accuracy: 0.6400\n",
      "Epoch 30/30\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0059 - categorical_accuracy: 0.9992\n",
      "Epoch 00030: saving model to model_init_2020-11-0919_52_33.773476/model-00030-0.00590-0.99925-1.17016-0.69000.h5\n",
      "34/34 [==============================] - 194s 6s/step - loss: 0.0059 - categorical_accuracy: 0.9992 - val_loss: 1.1702 - val_categorical_accuracy: 0.6900\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", rnn_cnn_tl_model.count_params())\n",
    "history_model17=rnn_cnn2.train_model(rnn_cnn_tl_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import mobilenet\n",
    "\n",
    "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "class CNN_RNN_GRU_TL(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,gru_cells=64,dense_neurons=64,dropout=0.25):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(mobilenet_transfer,input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    " \n",
    "        \n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(GRU(gru_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        \n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 16, 3, 3, 1024)    3228864   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 16, 3, 3, 1024)    4096      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 16, 1, 1, 1024)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 16, 1024)          0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 128)               443136    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,693,253\n",
      "Trainable params: 3,669,317\n",
      "Non-trainable params: 23,936\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_cnn_gru_tl=CNN_RNN_GRU_TL()\n",
    "rnn_cnn_gru_tl.initialize_path(project_folder)\n",
    "rnn_cnn_gru_tl.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn_gru_tl.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=20)\n",
    "rnn_cnn_gru_tl_model=rnn_cnn_gru_tl.define_model(gru_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn_gru_tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3693253\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:From <ipython-input-9-f23cee5fe61d>:125: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.1317 - categorical_accuracy: 0.5362 \n",
      "Epoch 00001: saving model to model_init_2020-11-0921_44_10.425982/model-00001-1.13167-0.53620-1.07881-0.55000.h5\n",
      "34/34 [==============================] - 1014s 30s/step - loss: 1.1317 - categorical_accuracy: 0.5362 - val_loss: 1.0788 - val_categorical_accuracy: 0.5500\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3538 - categorical_accuracy: 0.8688 \n",
      "Epoch 00002: saving model to model_init_2020-11-0921_44_10.425982/model-00002-0.35384-0.86878-0.47294-0.86000.h5\n",
      "34/34 [==============================] - 1176s 35s/step - loss: 0.3538 - categorical_accuracy: 0.8688 - val_loss: 0.4729 - val_categorical_accuracy: 0.8600\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3263 - categorical_accuracy: 0.8914 \n",
      "Epoch 00003: saving model to model_init_2020-11-0921_44_10.425982/model-00003-0.32629-0.89140-0.41467-0.86000.h5\n",
      "34/34 [==============================] - 1072s 32s/step - loss: 0.3263 - categorical_accuracy: 0.8914 - val_loss: 0.4147 - val_categorical_accuracy: 0.8600\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2799 - categorical_accuracy: 0.9012 \n",
      "Epoch 00004: saving model to model_init_2020-11-0921_44_10.425982/model-00004-0.27991-0.90121-0.63761-0.72000.h5\n",
      "34/34 [==============================] - 994s 29s/step - loss: 0.2799 - categorical_accuracy: 0.9012 - val_loss: 0.6376 - val_categorical_accuracy: 0.7200\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2121 - categorical_accuracy: 0.9231 \n",
      "Epoch 00005: saving model to model_init_2020-11-0921_44_10.425982/model-00005-0.21210-0.92308-0.42378-0.88000.h5\n",
      "34/34 [==============================] - 977s 29s/step - loss: 0.2121 - categorical_accuracy: 0.9231 - val_loss: 0.4238 - val_categorical_accuracy: 0.8800\n",
      "Epoch 6/20\n",
      "29/34 [========================>.....] - ETA: 2:37 - loss: 0.0983 - categorical_accuracy: 0.9724"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\",rnn_cnn_gru_tl_model.count_params())\n",
    "history_rnn_cnn_gru_tl=rnn_cnn_gru_tl.train_model(rnn_cnn_gru_tl_model,augment_data=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
